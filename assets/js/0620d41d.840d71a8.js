"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[7685],{87577:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var t=s(85893),o=s(11151);const r={sidebar_position:3,tags:["quickstart"]},d="Sandbox",i={id:"docs/setup/sandbox",title:"Sandbox",description:"The superduperdb open-source repository comes with a sandbox testing",source:"@site/content/docs/setup/sandbox.md",sourceDirName:"docs/setup",slug:"/docs/setup/sandbox",permalink:"/docs/docs/setup/sandbox",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/docs/setup/sandbox.md",tags:[{label:"quickstart",permalink:"/docs/tags/quickstart"}],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,tags:["quickstart"]},sidebar:"tutorialSidebar",previous:{title:"Configure",permalink:"/docs/docs/setup/configuration"},next:{title:"Testing",permalink:"/docs/docs/setup/testing"}},c={},l=[];function a(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,o.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"sandbox",children:"Sandbox"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsxs)(n.a,{href:"https://github.com/SuperDuperDB/superduperdb",children:[(0,t.jsx)(n.code,{children:"superduperdb"})," open-source repository"]})," comes with a sandbox testing\nenvironment. The sandbox is implemented in ",(0,t.jsx)(n.code,{children:"docker-compose"})," and includers containers for each of the services\nincluded in ",(0,t.jsx)(n.code,{children:"superduperdb"}),". View the details of the setup ",(0,t.jsx)(n.a,{href:"https://github.com/SuperDuperDB/superduperdb/blob/main/deploy/testenv/docker-compose.yaml",children:"here"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["In this environment, users can test and get a feel for a full ",(0,t.jsx)(n.code,{children:"superduperdb"})," setup, without the need to configure cloud environments or kubernetes setups. This environment may be used as inspiration for a more scalable, production-ready setup."]}),"\n",(0,t.jsx)(n.p,{children:"To build this environment first checkout the project if you haven't already:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone git@github.com:SuperDuperDB/superduperdb\ncd superduperdb\n"})}),"\n",(0,t.jsx)(n.p,{children:"Then build the docker image required to run the environment:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"make testenv_image\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["If you want to install additional ",(0,t.jsx)(n.code,{children:"pip"})," dependencies in the image, you have to list them in ",(0,t.jsx)(n.code,{children:"requirements.txt"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"The listed dependencies may refer to:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["standalone packages (e.g ",(0,t.jsx)(n.code,{children:"tensorflow>=2.15.0"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:["dependency groups listed in ",(0,t.jsx)(n.code,{children:"pyproject.toml"})," (e.g ",(0,t.jsx)(n.code,{children:".[dev]"}),")"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Now add these configurations to your setup by running:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"mkdir -p .superduperdb\ncat << Multi > .superduperdb/config.yaml\ndata_backend: mongodb://superduper:superduper@mongodb:27017/test_db\ncluster:\n  cdc: http://cdc:8001\n  compute: dask://scheduler:8786\n  vector_search: in_memory://vector-search:8000\nMulti\n"})}),"\n",(0,t.jsx)(n.p,{children:"To start the environment run:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"make testenv_init\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This uses ",(0,t.jsx)(n.code,{children:"docker-compose"})," to spin up:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["local testing ",(0,t.jsx)(n.code,{children:"mongodb"})," deployment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"jupyter"})," notebook environment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"dask"})," scheduler"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"dask"})," worker"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"cdc"})," service"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"vector-search"})," service"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"To stop the environment run:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"make testenv_shutdown\n"})}),"\n",(0,t.jsx)(n.h1,{id:"known-issues",children:"Known Issues"}),"\n",(0,t.jsxs)(n.p,{children:["To make sure data is saved between restarts, we connect a local data location to the ",(0,t.jsx)(n.code,{children:"mongodb"})," container.\nThe location is specified in the ",(0,t.jsx)(n.code,{children:"SUPERDUPERDB_DATA_DIR"})," of the Makefile and is initially set to ",(0,t.jsx)(n.code,{children:"deploy/testenv/.test_data"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["However, since the ",(0,t.jsx)(n.code,{children:"mongodb"})," container runs as 'root', the data directory will be owned by ",(0,t.jsx)(n.code,{children:"root"}),", and you'll need ",(0,t.jsx)(n.code,{children:"sudo"})," to delete it later."]})]})}function u(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>i,a:()=>d});var t=s(67294);const o={},r=t.createContext(o);function d(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:d(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);