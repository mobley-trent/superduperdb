"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[3377],{89250:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var t=s(85893),o=s(11151);const r={},i="Image features",a={id:"use_cases/classical_tasks/resnet_features",title:"Image features",description:"In this example, we show how to utilize a pre-trained network from torchvision to produce image features. The images are automatically fetched and stored in MongoDB. We use a subset of the CoCo dataset (https://cocodataset.org/#home) to illustrate the process.",source:"@site/content/use_cases/classical_tasks/resnet_features.md",sourceDirName:"use_cases/classical_tasks",slug:"/use_cases/classical_tasks/resnet_features",permalink:"/docs/use_cases/classical_tasks/resnet_features",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/use_cases/classical_tasks/resnet_features.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"MNIST classifier",permalink:"/docs/use_cases/classical_tasks/mnist_torch"},next:{title:"Sentiment analysis",permalink:"/docs/use_cases/classical_tasks/sentiment_analysis_use_case"}},c={},l=[{value:"Connect to Datastore",id:"connect-to-datastore",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"image-features",children:"Image features"}),"\n",(0,t.jsxs)(n.h1,{id:"building-an-image-feature-database-in-torchvision",children:["Building an Image Feature Database in ",(0,t.jsx)(n.code,{children:"torchvision"})]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"!pip install superduperdb==0.0.12\n!pip install torchvision\n"})}),"\n",(0,t.jsxs)(n.p,{children:["In this example, we show how to utilize a pre-trained network from ",(0,t.jsx)(n.code,{children:"torchvision"})," to produce image features. The images are automatically fetched and stored in MongoDB. We use a subset of the CoCo dataset (",(0,t.jsx)(n.a,{href:"https://cocodataset.org/#home",children:"https://cocodataset.org/#home"}),") to illustrate the process."]}),"\n",(0,t.jsxs)(n.p,{children:["Real-life use cases for creating a database of image features using a pre-trained network in ",(0,t.jsx)(n.code,{children:"torchvision"}),":"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Image Search and Retrieval:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use Case:"})," Enhance image search capabilities in e-commerce platforms."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"How:"})," Generate image features for products using a pre-trained network. Store these features in a database for efficient image retrieval, making it easier for users to find similar products."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Content-Based Recommendation Systems:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use Case:"})," Improve content recommendations in media streaming services."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"How:"})," Extract image features from movie or show frames. Store these features in a database to recommend content with similar visual characteristics to users based on their preferences."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Facial Recognition in Security Systems:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use Case:"})," Strengthen facial recognition systems in security applications."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"How:"})," Utilize a pre-trained neural network to extract facial features from images. Store these features in a database for quick and accurate identification in security and surveillance scenarios."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Medical Image Analysis:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use Case:"})," Assist in medical diagnostics through image analysis."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"How:"})," Extract features from medical images (X-rays, MRIs, etc.) using a pre-trained network. Store these features to aid in the development of diagnostic tools or systems for healthcare professionals."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Automated Image Tagging:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use Case:"})," Streamline image organization in photo libraries or social media platforms."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"How:"})," Extract features from uploaded images using a pre-trained model. Use these features to automatically generate relevant tags, making it easier for users to search and categorize their photos."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["These use cases demonstrate how creating a database of image features using ",(0,t.jsx)(n.code,{children:"torchvision"})," can be applied across various domains to enhance functionality and improve user experiences. Guess what, all can be done with ",(0,t.jsx)(n.code,{children:"superduperdb"})," like this example."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Download the zip file\n!curl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/valsmall2014.zip\n\n# Unzip the contents of the zip file (assuming the file is already downloaded)\n!unzip -qq valsmall2014.zip\n"})}),"\n",(0,t.jsx)(n.h2,{id:"connect-to-datastore",children:"Connect to Datastore"}),"\n",(0,t.jsxs)(n.p,{children:["First, we need to establish a connection to a MongoDB datastore via SuperDuperDB. You can configure the ",(0,t.jsx)(n.code,{children:"MongoDB_URI"})," based on your specific setup."]}),"\n",(0,t.jsx)(n.p,{children:"Here are some examples of MongoDB URIs:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For testing (default connection): ",(0,t.jsx)(n.code,{children:"mongomock://test"})]}),"\n",(0,t.jsxs)(n.li,{children:["Local MongoDB instance: ",(0,t.jsx)(n.code,{children:"mongodb://localhost:27017"})]}),"\n",(0,t.jsxs)(n.li,{children:["MongoDB with authentication: ",(0,t.jsx)(n.code,{children:"mongodb://superduper:superduper@mongodb:27017/documents"})]}),"\n",(0,t.jsxs)(n.li,{children:["MongoDB Atlas: ",(0,t.jsx)(n.code,{children:"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>"})]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import os\nfrom superduperdb import superduper\nfrom superduperdb.backends.mongodb import Collection\n\n# Get the MongoDB URI from the environment variable or use a default value\nmongodb_uri = os.getenv(\"MONGODB_URI\", \"mongomock://test\")\n\n# SuperDuperDB, now handles your MongoDB database\n# It just super dupers your database\ndb = superduper(mongodb_uri)\n\n# Specify a collection named 'coco'\ncollection = Collection('coco')\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Next, we include all image URIs in MongoDB. These URIs may include a mix of local file paths (",(0,t.jsx)(n.code,{children:"file://..."}),"), web URLs (",(0,t.jsx)(n.code,{children:"http..."}),"), and S3 URIs (",(0,t.jsx)(n.code,{children:"s3://..."}),"). Once the URIs are added, SuperDuperDB automatically loads their content into MongoDB without the need for extra overhead or job definitions."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import glob\nimport random\n\nfrom superduperdb import Document as D\nfrom superduperdb.ext.pillow import pil_image as i\n\n# Get a list of file URIs for all JPEG images in the 'valsmall2014' directory\nuris = [f'file://{x}' for x in glob.glob('valsmall2014/*.jpg')]\n\n# Insert documents into the 'coco' collection in the MongoDB database\ndb.execute(collection.insert_many([D({'img': i(uri=uri)}) for uri in uris], encoders=(i,)))  # Here the image is encoded with pillow\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To confirm the correct storage of images in the ",(0,t.jsx)(n.code,{children:"Datalayer"}),", we can perform a verification check."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Import the display function from the IPython.display module\nfrom IPython.display import display\n\n# Define a lambda function for displaying images with resizing to avoid potential Jupyter crashes\ndisplay_image = lambda x: display(x.resize((round(x.size[0] * 0.5), round(x.size[1] * 0.5))))\n\n# Retrieve the 'img' attribute from the result of collection.find_one() using db.execute()\n# Note: This assumes that db is an instance of a database connection wrapped with superduperdb\nx = db.execute(collection.find_one())['img'].x\n\n# Display the image using the previously defined lambda function\ndisplay_image(x)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Let's build the ",(0,t.jsx)(n.code,{children:"torch"})," + ",(0,t.jsx)(n.code,{children:"torchvision"})," model using the ",(0,t.jsx)(n.code,{children:"TorchModel"})," wrapper from SuperDuperDB. This allows for the incorporation of custom pre- and post-processing steps along with the model's forward pass."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Import necessary libraries and modules from torchvision and torch\nfrom torchvision import transforms\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nimport warnings\n\n# Import custom modules\nfrom superduperdb.ext.torch import TorchModel, tensor\n\n# Define a series of image transformations using torchvision.transforms.Compose\nt = transforms.Compose([\n    transforms.Resize((224, 224)),   # Resize the input image to 224x224 pixels (must same as here)\n    transforms.CenterCrop((224, 224)),  # Perform a center crop on the resized image\n    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the tensor with specified mean and standard deviation\n])\n\n# Define a preprocess function that applies the defined transformations to an input image\ndef preprocess(x):\n    try:\n        return t(x)\n    except Exception as e:\n        # If an exception occurs during preprocessing, issue a warning and return a tensor of zeros\n        warnings.warn(str(e))\n        return torch.zeros(3, 224, 224)\n\n# Load the pre-trained ResNet-50 model from torchvision\nresnet50 = models.resnet50(pretrained=True)\n\n# Extract all layers of the ResNet-50 model except the last one\nmodules = list(resnet50.children())[:-1]\nresnet50 = nn.Sequential(*modules)\n\n# Create a TorchModel instance with the Res\n\nNet-50 model, preprocessing function, and postprocessing lambda\nmodel = TorchModel(\n    identifier='resnet50',\n    preprocess=preprocess,\n    object=resnet50,\n    postprocess=lambda x: x[:, 0, 0],  # Postprocess by extracting the top-left element of the output tensor\n    encoder=tensor(torch.float, shape=(2048,))  # Specify the encoder configuration\n)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To ensure the correctness of the ",(0,t.jsx)(n.code,{children:"model"}),", let's test it on a single data point by setting ",(0,t.jsx)(n.code,{children:"one=True"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Assuming x is an input tensor, you're making a prediction using the configured model\n# with the one=True parameter specifying that you expect a single prediction result.\nmodel.predict(x, one=True)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Now that the model is prepared, we can apply it to the images stored in the ",(0,t.jsx)(n.code,{children:"Datalayer"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Assuming X is the input data, in this case, images ('img')\nprediction_results = model.predict(\n    X='img',                # Specify the input data (images)\n    db=db,                  # Provide the database connection or object\n    select=collection.find(),  # Specify the data to be used for prediction (fetch all data from the collection)\n    batch_size=10,          # Set the batch size for making predictions\n    max_chunk_size=3000,    # Set the maximum size of data chunks processed at once\n    in_memory=False,        # Indicate that the data is not loaded entirely into memory, processed in chunks\n    listen=True             # Enable listening mode, suggesting real-time or asynchronous prediction\n)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To confirm that the features were stored in the ",(0,t.jsx)(n.code,{children:"Datalayer"}),", you can examine them in the ",(0,t.jsx)(n.code,{children:"_outputs.img.resnet50"})," field."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Execute find_one() to retrieve a single document from the collection.\nresult = db.execute(collection.find_one())\n\n# The purpose of unpack() is to extract or process the data\nresult.unpack()\n"})})]})}function h(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>a,a:()=>i});var t=s(67294);const o={},r=t.createContext(o);function i(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);