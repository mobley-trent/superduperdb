"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[9493],{24387:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>i,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>l});var s=n(85893),d=n(11151);const o={sidebar_position:18},t="AI Models via Model and Descendants",a={id:"docs/walkthrough/ai_models",title:"AI Models via Model and Descendants",description:"AI models may be wrapped and used in superduperdb with the Model class and descendants.",source:"@site/content/docs/walkthrough/ai_models.md",sourceDirName:"docs/walkthrough",slug:"/docs/walkthrough/ai_models",permalink:"/docs/docs/walkthrough/ai_models",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/docs/walkthrough/ai_models.md",tags:[],version:"current",sidebarPosition:18,frontMatter:{sidebar_position:18},sidebar:"tutorialSidebar",previous:{title:"Working with and inserting large pieces of data",permalink:"/docs/docs/walkthrough/using_hybrid_storage_to_handle_large_data_blobs"},next:{title:"Using AI APIs as Predictor descendants",permalink:"/docs/docs/walkthrough/ai_apis"}},i={},l=[{value:"Creating AI Models in a Range of Frameworks",id:"creating-ai-models-in-a-range-of-frameworks",level:3},{value:"Vanilla",id:"vanilla",level:3},{value:"Scikit-Learn",id:"scikit-learn",level:3},{value:"Transformers",id:"transformers",level:3},{value:"PyTorch",id:"pytorch",level:3},{value:"Important Parameters, Common to All Models",id:"important-parameters-common-to-all-models",level:3}];function c(e){const r={a:"a",code:"code",h1:"h1",h3:"h3",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,d.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(r.h1,{id:"ai-models-via-model-and-descendants",children:["AI Models via ",(0,s.jsx)(r.code,{children:"Model"})," and Descendants"]}),"\n",(0,s.jsxs)(r.p,{children:["AI models may be wrapped and used in ",(0,s.jsx)(r.code,{children:"superduperdb"})," with the ",(0,s.jsx)(r.code,{children:"Model"})," class and descendants."]}),"\n",(0,s.jsx)(r.h3,{id:"creating-ai-models-in-a-range-of-frameworks",children:"Creating AI Models in a Range of Frameworks"}),"\n",(0,s.jsxs)(r.p,{children:["Model instances may be saved to ",(0,s.jsx)(r.code,{children:"superduperdb"})," using ",(0,s.jsx)(r.code,{children:"db.add"}),"."]}),"\n",(0,s.jsx)(r.h3,{id:"vanilla",children:"Vanilla"}),"\n",(0,s.jsxs)(r.p,{children:["By default, the ",(0,s.jsx)(r.code,{children:"Model"})," component supports arbitrary callables to be used to perform model predictions and transformations:"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:"from superduperdb import Model\n\ndef chunk_text(x):\n    return x.split('\\n\\n')\n\ndb.add(\n    Model(identifier='my-chunker', object=chunk_text)\n)\n"})}),"\n",(0,s.jsx)(r.h3,{id:"scikit-learn",children:"Scikit-Learn"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:"from superduperdb.ext.sklearn import Estimator\nfrom sklearn.svm import SVC\n\ndb.add(Estimator(SVC()))\n"})}),"\n",(0,s.jsx)(r.h3,{id:"transformers",children:"Transformers"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:"from superduperdb.ext.transformers import Pipeline\nfrom superduperdb import superduper\n\ndb.add(Pipeline(task='sentiment-analysis'))\n"})}),"\n",(0,s.jsxs)(r.p,{children:["There is also support for building the pipeline in separate stages with a high degree of customization.\nThe following is a speech-to-text model published by ",(0,s.jsx)(r.a,{href:"https://arxiv.org/abs/2010.05171",children:"facebook research"})," and shared ",(0,s.jsx)(r.a,{href:"https://huggingface.co/facebook/s2t-small-librispeech-asr",children:"on Hugging-Face"}),":"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:"from superduperdb.ext.transformers import Pipeline\nfrom transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n\nmodel = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\nprocessor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n\ntranscriber = Pipeline(\n    identifier='transcription',\n    object=model,\n    preprocess=processor,\n    preprocess_kwargs={'sampling_rate': SAMPLING_RATE, 'return_tensors': 'pt', 'padding': True}, # Please replace the placeholder `SAMPLING_RATE` with the appropriate value in your context.\n    postprocess=lambda x: processor.batch_decode(x, skip_special_tokens=True),\n    predict_method='generate',\n    preprocess_type='other',\n)\n\ndb.add(transcriber)\n"})}),"\n",(0,s.jsx)(r.h3,{id:"pytorch",children:"PyTorch"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:"import torch\nfrom superduperdb.ext.torch import Module\n\nmodel = Module(\n    identifier='my-classifier',\n    preprocess=lambda x: torch.tensor(x),\n    object=torch.nn.Linear(64, 512),\n    postprocess=lambda x: x.topk(1)[0].item(),\n)\n\ndb.add(model)\n"})}),"\n",(0,s.jsx)(r.h3,{id:"important-parameters-common-to-all-models",children:"Important Parameters, Common to All Models"}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Name"}),(0,s.jsx)(r.th,{children:"Function"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"identifier"})}),(0,s.jsxs)(r.td,{children:["A unique name for ",(0,s.jsx)(r.code,{children:"superduperdb"}),", for later use and recall"]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"object"})}),(0,s.jsx)(r.td,{children:"The model-object, including parameters and hyper-parameters providing heavy lifting"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"preprocess"})}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"Callable"})," which processes individual rows/records/fields from the database prior to passing to the model"]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"postprocess"})}),(0,s.jsxs)(r.td,{children:[(0,s.jsx)(r.code,{children:"Callable"})," applied to individual rows/items or output"]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"encoder"})}),(0,s.jsxs)(r.td,{children:["An ",(0,s.jsx)(r.code,{children:"Encoder"})," instance applied to the model output to save that output in the database"]})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"schema"})}),(0,s.jsxs)(r.td,{children:["A ",(0,s.jsx)(r.code,{children:"Schema"})," instance applied to a model's output, whose rows are dictionaries"]})]})]})]})]})}function h(e={}){const{wrapper:r}={...(0,d.a)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},11151:(e,r,n)=>{n.d(r,{Z:()=>a,a:()=>t});var s=n(67294);const d={},o=s.createContext(d);function t(e){const r=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:t(e.components),s.createElement(o.Provider,{value:r},e.children)}}}]);