"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[1477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"superduperdb-the-open-source-framework-for-bringing-ai-to-your-datastore","metadata":{"permalink":"/blog/superduperdb-the-open-source-framework-for-bringing-ai-to-your-datastore","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/v1/releasingv1.md","source":"@site/blog/v1/releasingv1.md","title":"Integrating AI directly with your databases to eliminate complex MLOps and vector databases","description":"\ud83d\udd2eTL;DR: We introduce SuperDuperDB, which has just published its first major v0.1 release. SuperDuperDB is an open-source AI development and deployment framework to seamlessly integrate AI models and APIs with your database. In the following, we will survey the challenges presented by current AI-data integration methods and tools, and how they motivated us in developing SuperDuperDB. We\'ll then provide an overview of SuperDuperDB, highlighting its core principles, features and existing integrations.","date":"2024-02-20T13:07:54.000Z","formattedDate":"February 20, 2024","tags":[{"label":"Launching Blog","permalink":"/blog/tags/launching-blog"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":9.56,"hasTruncateMarker":false,"authors":[{"name":"Duncan Blythe","title":"CTO & Co-founder of SuperDuperDB","url":"https://github.com/blythed","imageURL":"https://avatars.githubusercontent.com/u/15139331?v=4","key":"blythed"},{"name":"Timo Hagenow","title":"CEO & Co-founder of SuperDuperDB","url":"https://www.linkedin.com/in/timohagenow/","imageURL":"https://media.licdn.com/dms/image/D4E03AQGg35RuVoXOYQ/profile-displayphoto-shrink_400_400/0/1682109861734?e=1707350400&v=beta&t=XA8MDWVZRB58IOpc_p-hdX943x6GJ71Xiv-_Ne4N1aw","key":"timo"}],"frontMatter":{"slug":"superduperdb-the-open-source-framework-for-bringing-ai-to-your-datastore","title":"Integrating AI directly with your databases to eliminate complex MLOps and vector databases","authors":["blythed","timo"],"image":"/img/super_intro.png","tags":["Launching Blog","release"]},"unlisted":false,"nextItem":{"title":"How to efficiently build AI chat applications for your own documents with MongoDB Atlas","permalink":"/blog/2023/10/04/walkthrough-rag-app-atlas"}},"content":"\ud83d\udd2e**TL;DR:** *We introduce SuperDuperDB, which has just published its first major v0.1 release. SuperDuperDB is an open-source AI development and deployment framework to seamlessly integrate AI models and APIs with your database. In the following, we will survey the challenges presented by current AI-data integration methods and tools, and how they motivated us in developing SuperDuperDB. We\'ll then provide an overview of SuperDuperDB, highlighting its core principles, features and existing integrations.*\\n\\n![](/img/introduction.png)\\n\\n### AI adoption is pressing, but difficult\\n\\nAI is changing every industry and will soon play a central role in software products and services.\\n\\nDevelopers today may already choose from a growing number of powerful open-source AI models and APIs. Despite this, there are numerous challenges which face developers when integrating AI with data and bringing machine learning models to production.\\n\\n### AI and data live in silos separate from one another\\n\\nData is crucial for AI, and, most importantly, connecting AI with data is vital for delivering value whether in training models or applying models to application-relevant data. A key problem stems from the disconnect between where data resides (in databases) and the lack of a standard method for AI models to interface with these databases. This results in convoluted MLOps pipelines, involving intricate steps, numerous tools, and specialized vector databases, and contributes to the status quo in which data and AI live in isolated silos. \\n\\n### Connecting AI with your data to build custom AI is a big challenge \\n\\nCurrent solutions require extracting data from the database, and bringing it to AI models. More specifically, extracted data is ingested into complex \u201cMLOps\u201d and \u201cextract-transform-load\u201d (ETL) pipelines that involve various steps, tools, and even specialized \u201cvector-databases\u201d and \u201cfeature-stores\u201d. These convoluted pipelines involve sending the data back and forth, from one environment, format, location, or programming language to another.\\n\\n![](/img/complex_pipelines.png)\\n\\nIn setting up these pipelines, developers are forced to implement a different version of the same task every time they wish to productionize an AI model. Each sub-step of this process may involve multiple sets of installation targets, cloud setups, docker containers, and computational environments. Since every model has its own particular interface and requirements, this leads to huge operational and infrastructural overhead, which multiplies with the number of models, data types, databases, and hardware requirements.\\n\\nThis becomes increasingly difficult when:\\n\\n- data is constantly updated and changing\\n- data resides in multiple locations,\\n- data security restrictions disallow the use of AI APIs and require end-to-end self hosting.\\n\\nDue to this complexity, both individual developers and teams often struggle to put AI-powered applications into production, lacking the required expert knowledge in various domains, and unable to meet the prohibitive costs of deploying and maintaining such pipelines.\\n\\n### Low-code AI tools and cloud-managed AI often don\u2019t fit the bill\\n\\nA new wave of AI companies and services offer \\"few-click\\" interfaces and \\"low-code markups\\" to ease AI-data integration for certain use-cases. However, these fall short of wide applicability. User-interfaces are typically too far removed from the nuts and bolts of AI models to become broadly useful; low-code mark-up languages hide the most important details of AI implementation from the user and render it impossible to override baked in defaults. This means that as soon as an application departs from the most commonly used and documented AI use-cases, developers are left without options for customization.\\n\\nOn the other hand, services of the major cloud providers also make the promise to simplify AI and data integration. These offerings presents two major issues: developers are encouraged to give up full ownership of their stack, leading to costly vendor lock-in. What\u2019s more, these services do little more than repackage traditional MLOps and ETL pipelines, still resulting in substantial developer overhead.\\n\\n### The problem with vector databases\\n\\nThe popularity of vector-databases, alongside tools such as LangChain and LlamaIndex, has surged in 2023. This boom has been fuelled by the prospect of combining vector-searches with LLMs and the fact that standard databases lack the necessary vector-search functionality, model support, and support for flexible data types required. While these tools allow developers to get started with vector-search quickly, the reality is that, in production, primary data resides in, and will most likely remain in established databases. This means that developers are required to introduce an *additional* specialized database, for this single purpose, to their stacks, leading to data duplication, migration, and management overhead. If data is already stored in an existing, preferred and battle-tested database, then why not simply leave the data there? \\n\\n# Unifying data and AI\\n\\nWe believe, unifying data and AI in a single environment is the key to facilitating AI adoption. By doing this, the difficulties encountered with MLOps, ETL and vector-databases can be completely avoided.\\n\\nSpecifically, developers need an environment that can work directly with data in the database, enabling flexible integration of AI models, and vector-search, with minimal boilerplate. Ideally this environment should allow developers to connect a model to the database, so that it automatically processes incoming data, making economical use of resources.\\n\\n# Enter SuperDuperDB\\n![](/img/SuperDuperDB_GitHub_Repo.png)\\n\\nSuperDuperDB\u2019s mission is to bring AI to the database, making data migration, data duplication, MLOps, and ETL pipelines things of the past. \\n\\nSuperDuperDB is a general-purpose AI development and deployment framework for integrating any AI models (including enhanced support for PyTorch, Scikit-Learn, Hugging Face) and AI APIs (including enhanced support for OpenAI, Anthrophic, Cohere) directly with existing databases, including streaming inference, model training, and vector search. SuperDuperDB is **not** a database, it **makes** your existing databases \u201csuper-duper\u201d.\\n\\n```python\\nfrom superduperdb import superduper\\n\\n# Make your database super-duper!\\ndb = superduper(\'mongodb|postgres|duckdb|snowflake|://<connection-uri>\')\\n```\\n\\nBy bringing AI directly to data, solo developers and organizations can avoid the complexity of building and integrating MLOps and ETL pipelines as well as migrating and duplicating data across multiple environments, including specialized vector databases. SuperDuperDB enables the integration of AI with data in the database, storing AI model outputs alongside the source data. These insights and AI outputs are then ready for instant deployment in downstream applications.\\n\\nSuperDuperDB provides a unified environment for building, shipping, and managing AI applications, including first-class support for:\\n\\n- Generative AI & LLM-chat applications\\n- Vector search\\n- Standard machine learning use-cases (classification, segmentation, recommendation, etc.)\\n- Highly custom AI use-cases involving application specific, home-grown models.\\n\\n:::info Support us by leaving a star\\n\ud83d\udd2e Please support us by leaving a star the GitHub repo and share it with anyone who could be interested: [https://github.com/SuperDuperDB/superduperdb](https://github.com/SuperDuperDB/superduperdb)\\n:::\\n\\n## Core principles and features of SuperDuperDB\\n\\n### Open source\\n\\nWe believe AI software should be open-sourced to the community. Truly open-source tools are the only sure way for developers to protect their stacks from vunerable dependencies.\\n\\nWith SuperDuperDB, we are excited to be part of a thriving open-source AI ecosystem. There is a wealth of open-source AI software and models available, including `transformers` from Hugging Face, `llama-2.0` and other LLMs that can compete with OpenAI\'s closed source models, computer vision models in PyTorch, and a plethora of new open-source tools and models emerging from GitHub.\\n\\nSuperDuperDB is permissively open-sourced under the Apache-2.0 license, and aims to become a leading standard in adopting and extracting value from this ecosystem.\\n\\n### **Python first**\\n\\nMany tools on the AI landscape encourage developers to move away from Python, in favour of specialized user-interfaces, or specific mark-up languages only relevant to the tool in question. This not only ignores the important fact that Python is the programming language of AI research,  development and tooling, but the advertised simplicity comes at the great cost of flexibility.\\n\\nBy building SuperDuperDB as an open-source Python package, we are able to provide a simple interface with high-level abstractions for users who wish to get started quickly with AI models, but enabling experts to drill down to any level of implementation detail.\\n\\nBy deploying models directly to the database from Python, there is no overhead incurred by task-switching to other programming languages or environments. Using SuperDuperDB developers may:\\n\\n- add, leverage and work with any function, program, script or algorithm from the Python ecosystem to enhance workflows and applications.\\n- retain full control over the inner workings of models and training configurations\\n- combine SuperDuperDB with favoured tooling such as the vastly popular FastAPI. ([See here for an open-source chatbot implementation based on SuperDuperDB and FastAPI](https://github.com/SuperDuperDB/chat-with-your-docs-backend), which showcases how easily SuperDuperDB and the Python ecosystem interact.)\\n- interface with their database using SuperDuperDB directly from a Jupyter notebook - the data scientist\u2019s development environment of choice.\\n\\n### Avoid **complex pipelines**\\n\\nArbitrary pipeline builders, as offered in typical MLOps tooling, typically consist of repeated rounds of ETL, with a variety of models and processors. By understanding the patterns which AI developers typically apply, we were able to build a framework which avoids the necessity of pipeline building while leveraging compute in the most efficient way possible.\\n\\nAs a result, SuperDuperDB allows developers to:\\n\\n- avoid data duplication and migration.\\n- avoid additional pre-processing steps, ETL, and boilerplate code.\\n- activate models to compute outputs automatically as new data arrives, keeping deployments up-to-date.\\n- train AI models on large datasets, utilizing the in-built scalability of SuperDuperDB.\\n- set up complex workflows by connecting models and APIs to work together in an interdependent and sequential manner.\\n\\n### Avoid specialized vector databases\\n\\nWith SuperDuperDB, there is no need to duplicate and migrate data to additional specialized vector databases \u2014 your existing database becomes a fully-fledged multi-modal vector-search database, with support for arbitrary data types, and generation of vector embeddings and vector indexes of your data with arbitrary AI models and APIs.\\n\\n### Support for arbitrary data types\\n\\nSuperDuperDB supports images, video, and arbitrary data-types which may be defined in Python; this includes efficient use of hybrid database-filesystem storage, allowing developers to make the most effective use of storage modalities and achieve great I/O performance.\\n\\n### First-class support for generative AI as well as classical machine learning\\n\\nSuperDuperDB levels the playing field for all AI models, regardless of complexity. Setting up applications such as retrieval-augmented-generation (RAG) chatbots, which combine generative AI and vector search, is as easy as setting up a wide range of industry use-cases involving tabular data, time-series, and more, all of which still hold immense value. Even applications that combine generative AI with classical ML algorithms can be seamlessly integrated into a single workflow.\\n\\n![](/img/firstclass.png)\\n\\n# Current Integrations:\\n\\n### Datastores:\\n\\n![](/img/datastore.png)\\n\\n### AI Frameworks & APIs: \\n![](/img/AI1.png)\\n![](/img/AI2.png)\\n\\n\\n# Use-cases and applications\\n\\nWe have already implemented numerous use-cases and applications, such as LLM RAG chat, forecasting, recommenders, sentiment analysis which you can refer to in the [README of our main repository](https://github.com/SuperDuperDB/superduperdb) and in our [example use cases documentation](https://docs.superduperdb.com/docs/category/use-cases) \\n\\n![](/img/usecase.png)\\n\\nIn addition, we already have several impressive applications and use-cases built by the open-source community, which we are excited to present in our dedicated community apps showcase repo: [SuperDuperDB Community Apps](https://github.com/SuperDuperDB/superduper-community-apps).\\n\\n# Vision, roadmap, and how to get started\\n\\nAfter reviewing the use cases, you\u2019ll be ready to build your own AI applications using your own database. For assistance, please refer to our [documentation](https://docs.superduperdb.com/docs/docs/intro) and join our [Slack](https://superduperdb.slack.com/join/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA#/shared-invite/email). We would also love to hear about your project and help you to share it with the community.\\n\\nThe current focus of the roadmap is making the deployment of SuperDuperDB absolutely production-ready and to improve optimizations for deployment, compute efficiency and scalability. \\n\\n:::info Leave a star\\n\u2764\ufe0f\u200d\ud83d\udd25 If you haven\u2019t yet, now is the time to leave a star on GitHub to support the project and share it with your friends and colleagues: https://github.com/SuperDuperDB/superduperdb\\n:::"},{"id":"/2023/10/04/walkthrough-rag-app-atlas","metadata":{"permalink":"/blog/2023/10/04/walkthrough-rag-app-atlas","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-10-04-walkthrough-rag-app-atlas.md","source":"@site/blog/2023-10-04-walkthrough-rag-app-atlas.md","title":"How to efficiently build AI chat applications for your own documents with MongoDB Atlas","description":"*Despite the huge surge in popularity in building AI applications with LLMs and vector search,","date":"2023-10-04T00:00:00.000Z","formattedDate":"October 4, 2023","tags":[],"readingTime":3.455,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Integrating AI directly with your databases to eliminate complex MLOps and vector databases","permalink":"/blog/superduperdb-the-open-source-framework-for-bringing-ai-to-your-datastore"},"nextItem":{"title":"Walkthrough: How to enable and manage MongoDB Atlas Vector Search with SuperDuperDB","permalink":"/blog/2023/09/31/a-walkthrough-of-vector-search-on-mongodb-atlas-with-superduperdb/content"}},"content":"*Despite the huge surge in popularity in building AI applications with LLMs and vector search,\\nwe haven\'t seen any walkthroughs boil this down to a super-simple, few-command process.\\nWith SuperDuperDB together with MongoDB Atlas, it\'s easier and more flexible than ever before.*\\n\\n:::info\\nWe have built and deployed an AI chatbot for questioning technical documentation to showcase how efficiently and flexibly you can build end-to-end Gen-AI applications on top of MongoDB with SuperDuperDB: https://www.question-the-docs.superduperdb.com/ \\n:::\\n\\nImplementing a (RAG) chat application like a question-your-documents service can be a tedious and complex process. There are several steps involved in doing this:\\n\\n\x3c!--truncate--\x3e\\n\\n- Serve a model or forward requests to convert text-data in the database to vectors in a vector-database\\n- Setting up a vector-index in a vector-database which efficiently finds similar vectors\\n- Setting up an endpoint to either run a self hosted LLM  or forward requests to a question-answering LLM such as OpenAI\\n- Setting up an endpoint to:\\n  - Convert a question to a vector\\n  - Find relevant documents to the question using vector-search\\n  - Send the documents as context to the question-answering LLM\\n\\nThis process can be tedious and complex, involving several pieces of infrastructure, especially\\nif developers would like to use other models than those hosted behind OpenAI\'s API.\\n\\nWhat if we told you that with SuperDuperDB together with MongoDB Atlas, these challenges are a thing of the past, \\nand can be done more simply than with any other solution available?\\n\\nLet\'s dive straight into the solution:\\n\\n**Connect to MongoDB Atlas with SuperDuperDB**\\n\\n```python\\nfrom superduperdb.db.base.build import build_datalayer\\nfrom superduperdb import CFG\\nimport os\\n\\nATLAS_URI = \\"mongodb+srv://<user>@<atlas-server>/<database_name>\\"\\nOPENAI_API_KEY = \\"<your-open-ai-api-key>\\"\\n\\nos.environ[\\"OPENAI_API_KEY\\"] = OPENAI_API_KEY\\n\\nCFG.data_backend = ATLAS_URI\\nCFG.vector_search = ATLAS_URI\\n\\ndb = build_datalayer()\\n```\\n\\nAfter connecting to SuperDuperDB, setting up question-your-documents in Python boils down to 2 commands.\\n\\n**Set up a vector-index**\\n\\n```python\\nfrom superduperdb.container.vector_index import VectorIndex\\nfrom superduperdb.container.listener import Listener\\nfrom superduperdb.ext.openai.model import OpenAIEmbedding\\n\\ncollection = Collection(\'documents\')\\n\\ndb.add(\\n    VectorIndex(\\n        identifier=\'my-index\',\\n        indexing_listener=Listener(\\n            model=OpenAIEmbedding(model=\'text-embedding-ada-002\'),\\n            key=\'txt\',\\n            select=collection.find(),\\n        ),\\n    )\\n)\\n```\\n\\nIn this code snippet, the model used for creating vectors is `OpenAIEmbedding`. This is completely configurable.\\nYou can also use:\\n\\n- CohereAI API\\n- Hugging-Face `transformers`\\n- `sentence-transformers`\\n- Self built models in `torch`\\n\\nThe `Listener` component sets up this model to listen for new data, and compute new vectors as this data comes in.\\n\\nThe `VectorIndex` connects user queries with the computed vectors and the model.\\n\\nBy adding this nested component to `db`, the components are activated and ready to go for vector-search.\\n\\n**Add a question-answering component**\\n\\n```python\\nfrom superduperdb.ext.openai.model import OpenAIChatCompletion\\n\\nchat = OpenAIChatCompletion(\\n    model=\'gpt-3.5-turbo\',\\n    prompt=(\\n        \'Use the following content to answer this question\\\\n\'\\n        \'Do not use any other information you might have learned\\\\n\'\\n        \'Only base your answer on the content provided\\\\n\'\\n        \'{context}\\\\n\\\\n\'\\n        \'Here\\\\\'s the question:\\\\n\'\\n    ),\\n)\\n\\ndb.add(chat)\\n```\\n\\nThis command creates and configures an LLM hosted on OpenAI to operate together with MongoDB.\\nThe prompt can be configured to ingest the context using the `{context}` format variable.\\nThe results of the vector search are pasted into this format variable.\\n\\n**Question your documents!**\\n\\n```python\\ninput = \'Explain to me the reasons for the change of strategy in the company this year.\'\\n\\nresponse, context = db.predict(\\n    \'gpt-3.5-turbo\',\\n    input=input,\\n    context=collection.like({\'txt\': input}, vector_index=\'my-index\').find()\\n)\\n```\\n\\nThis command executes the vector-search query in the `context` parameter. The results of \\nthis search are added to the prompt to prime the LLM to ground its answer on the documents\\nin MongoDB.\\n\\n### Useful Links\\n\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"},{"id":"/2023/09/31/a-walkthrough-of-vector-search-on-mongodb-atlas-with-superduperdb/content","metadata":{"permalink":"/blog/2023/09/31/a-walkthrough-of-vector-search-on-mongodb-atlas-with-superduperdb/content","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-09-31-a-walkthrough-of-vector-search-on-mongodb-atlas-with-superduperdb/content.md","source":"@site/blog/2023-09-31-a-walkthrough-of-vector-search-on-mongodb-atlas-with-superduperdb/content.md","title":"Walkthrough: How to enable and manage MongoDB Atlas Vector Search with SuperDuperDB","description":"*In step-by-step tutorial we will show how to leverage MongoDB Atlas Vector Search","date":"2023-10-01T00:00:00.000Z","formattedDate":"October 1, 2023","tags":[],"readingTime":3.755,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"How to efficiently build AI chat applications for your own documents with MongoDB Atlas","permalink":"/blog/2023/10/04/walkthrough-rag-app-atlas"},"nextItem":{"title":"Jumpstart AI development on MongoDB with SuperDuperDB","permalink":"/blog/2023/09/30/jump-start-ai-development"}},"content":"*In step-by-step tutorial we will show how to leverage MongoDB Atlas Vector Search\\nwith SuperDuperDB, including the generation of vector embeddings. Learn how to connect embedding APIs such as OpenAI or use embedding models for example from HuggingFace with MongoDB Atlas with simple Python commands.*\\n\\n:::info\\nSuperDuperDB makes it very easy to set up multimodal vector search with different file types (text, image, audio, video, and more). \\n:::\\n\\n\\n\\n**Install `superduperdb` Python package**\\n\\nUsing vector-search with SuperDuperDB on MongoDB requires only one simple python package install:\\n\\n\x3c!--truncate--\x3e\\n\\n```bash\\npip install superduperdb\\n```\\n\\nWith this install SuperDuperDB includes all the packages needed to define a range of API based and package based \\nvector-search models, such as OpenAI and Hugging-Face\'s `transformers`.\\n\\n**Connect to your Atlas cluster using SuperDuperDB**\\n\\nSuperDuperDB ships with it\'s own MongoDB python client, which supports\\nall commands supported by `pymongo`. In the example below \\nthe key to connecting to your Atlas cluster is the `db` object.\\n\\nThe `db` object contains all functionality needed to read and write to \\nthe MongoDB instance and also to define, save and apply a flexible range \\nof AI models for vector-search.\\n\\n```python\\nfrom superduperdb.db.base.build import build_datalayer\\nfrom superduperdb import CFG\\nimport os\\n\\nATLAS_URI = \\"mongodb+srv://<user>@<atlas-server>/<database_name>\\"\\nOPENAI_API_KEY = \\"<your-open-ai-api-key>\\"\\n\\nos.environ[\\"OPENAI_API_KEY\\"] = OPENAI_API_KEY\\n\\nCFG.data_backend = ATLAS_URI\\nCFG.vector_search = ATLAS_URI\\n\\ndb = build_datalayer()\\n```\\n\\n**Load your data**\\n\\nYou can download some data to play with from [this link](https://superduperdb-public.s3.eu-west-1.amazonaws.com/pymongo.json):\\n\\n```bash\\ncurl -O https://superduperdb-public.s3.eu-west-1.amazonaws.com/pymongo.json\\n```\\n\\nThe data contains all inline doc-strings of the `pymongo` Python API (official\\nMongoDB driver for Python). The name of the function or class is in `\\"res\\"` and\\nthe doc-string is contained in `\\"value\\"`.\\n\\n```python\\nimport json\\n\\nwith open(\'pymongo.json\') as f:\\n    data = json.load(f)\\n```\\n\\nHere\'s one record to illustrate the data:\\n\\n```json\\n{\\n  \\"key\\": \\"pymongo.mongo_client.MongoClient\\",\\n  \\"parent\\": null,\\n  \\"value\\": \\"\\\\nClient for a MongoDB instance, a replica set, or a set of mongoses.\\\\n\\\\n\\",\\n  \\"document\\": \\"mongo_client.md\\",\\n  \\"res\\": \\"pymongo.mongo_client.MongoClient\\"\\n}\\n```\\n\\n**Insert the data into your Atlas cluster**\\n\\nWe can use the SuperDuperDB connection to insert this data\\n\\n```python\\nfrom superduperdb.db.mongodb.query import Collection\\n\\ncollection = Collection(\'documents\')\\n\\ndb.execute(\\n    collection.insert_many([\\n        Document(r) for r in data\\n    ])\\n)\\n```\\n\\n**Define your vector model and vector-index**\\n\\nNow we have data in our collection we can define the vector-index:\\n\\n```python\\nfrom superduperdb.container.vector_index import VectorIndex\\nfrom superduperdb.container.listener import Listener\\nfrom superduperdb.ext.numpy.array import array\\nfrom superduperdb.ext.openai.model import OpenAIEmbedding\\n\\nmodel = OpenAIEmbedding(model=\'text-embedding-ada-002\')\\n\\ndb.add(\\n    VectorIndex(\\n        identifier=f\'pymongo-docs\',\\n        indexing_listener=Listener(\\n            model=model,\\n            key=\'value\',\\n            select=Collection(\'documents\').find(),\\n            predict_kwargs={\'max_chunk_size\': 1000},\\n        ),\\n    )\\n)\\n```\\n\\nThis command tells the system that we want to:\\n\\n- search the `\\"documents\\"` collection\\n- set-up a vector-index on our Atlas cluster, using the text in the `\\"value\\"` field\\n- use the OpenAI model `\\"text-embedding-ada-002\\"` to create vector-embeddings\\n\\nAfter issuing this command, SuperDuperDB does these things:\\n\\n- Configures an MongoDB Atlas knn-index in the `\\"documents\\"` collection\\n- Saves the `model` object in the SuperDuperDB model store hosted on `gridfs`\\n- Applies `model` to all data in the `\\"documents\\"` collection, and saves the vectors in the documents\\n- Saves the fact that `model` is connected to the `\\"pymongo-docs\\"` vector-index\\n\\nYou can confirm that the index has been created and view the index\'s settings \\nin the [Atlas UI](https://cloud.mongodb.com/). It should look like this:\\n\\n![](atlas_screen.png)\\n\\nThe nesting of the index signifies the fact that the index created looks \\ninto the `_outputs.<key>.<model-name>` path, which is where the model\'s vector outputs are stored\\nautomatically by SuperDuperDB.\\n\\n**Use vector-search in a super-duper query**\\n\\nNow we are ready to use the SuperDuperDB query-API for vector-search.\\nYou\'ll see below, that SuperDuperDB handles all logic related to \\nconverting queries on the fly to vectors under the hood.\\n\\n```python\\nfrom superduperdb.db.mongodb.query import Collection\\nfrom superduperdb.container.document import Document as D\\nfrom IPython.display import *\\n\\nquery = \'Find data\'\\n\\nresult = db.execute(\\n    Collection(\'documents\')\\n        .like(D({\'value\': query}), vector_index=\'pymongo-docs\', n=5)\\n        .find()\\n)\\n\\nfor r in result:\\n    display(Markdown(f\'### `{r[\\"parent\\"] + \\".\\" if r[\\"parent\\"] else \\"\\"}{r[\\"res\\"]}`\'))\\n    display(Markdown(r[\'value\']))\\n```\\n\\n### Useful Links\\n\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"},{"id":"/2023/09/30/jump-start-ai-development","metadata":{"permalink":"/blog/2023/09/30/jump-start-ai-development","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-09-30-jump-start-ai-development.md","source":"@site/blog/2023-09-30-jump-start-ai-development.md","title":"Jumpstart AI development on MongoDB with SuperDuperDB","description":"MongoDB now supports vector-search on Atlas enabling developers to build next-gen AI applications directly on their favourite database. SuperDuperDB now make this process painless by allowing to integrate, train and manage any AI models and APIs directly with your database with simple Python.","date":"2023-09-30T00:00:00.000Z","formattedDate":"September 30, 2023","tags":[],"readingTime":2.735,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Walkthrough: How to enable and manage MongoDB Atlas Vector Search with SuperDuperDB","permalink":"/blog/2023/09/31/a-walkthrough-of-vector-search-on-mongodb-atlas-with-superduperdb/content"},"nextItem":{"title":"SuperDuperDB now supports Cohere and Anthropic APIs","permalink":"/blog/2023/09/29/superduperdb-now-supports-cohere-and-anthropic-apis"}},"content":"MongoDB now supports vector-search on Atlas enabling developers to build next-gen AI applications directly on their favourite database. SuperDuperDB now make this process painless by allowing to integrate, train and manage any AI models and APIs directly with your database with simple Python.\\n\\nBuild next-gen AI applications - without the need of complex MLOps pipelines and infrastructure nor data duplication and migration to specialized vector databases:\\n\\n- **(RAG) chat applications** on documents hosted in MongoDB Atlas\\n- **semantic-text-search & similiarity-search,** using vector embeddings of your data stored in Atlas \\n- **image similarity & image-search** on images hosted in or referred to on MongoDB Atlas\\n- **video search** including search *within* videos for key content\\n- **content based recommendation** based on content hosted in MongoDB Atlas\\n- **...and much, much more!**\\n\\n\x3c!--truncate--\x3e\\n\\n## Using SuperDuperDB to get started with Atlas vector-search\\n\\nThere is great content on the MongoDB website on how to [get started with vector-search on Atlas](https://www.mongodb.com/library/vector-search/building-generative-ai-applications-using-mongodb). You\'ll see that there are several steps involved:\\n\\n1. Preparing documents for vector-search\\n2. Converting text into vectors with an AI \\"model\\" and storing these vectors in MongoDB\\n3. Setting up a vector-search index on Atlas vector-search\\n4. Preparing a production API endpoint to convert searches in real time to vectors\\n\\nEach of these steps contains several sub-steps, and can become quite a headache for developers wanting to get started with vector-search.\\n\\nWith SuperDuperDB, this preparation process can be boiled down to one simple command:\\n\\n```python\\nfrom superduperdb.ext.openai.model import OpenAIEmbedding\\nfrom superduperdb.container.vector_index import VectorIndex\\nfrom superduperdb.container.listener import Listener\\nfrom superduperdb.db.mongodb.query import Collection\\n\\ndb.add(\\n    VectorIndex(\\n        identifier=\'my-index\',\\n        indexing_listener=Listener(\\n            model=OpenAIEmbedding(model=\'text-embedding-ada-002\'),\\n            key=\'key\',  # path of documents\\n            select=Collection(\'documents\').find(),\\n            predict_kwargs={\'max_chunk_size\': 1000},\\n        ),\\n    )\\n)\\n```\\n\\nUnder the hood SuperDuperDB does these things:\\n\\n1. Sets up an Atlas vector-search index in the `\\"documents\\"` collection\\n2. Converts all documents into vectors\\n3. Creates a function allow users to directly search using vectors, without needing to handle the conversion to vectors themselves: `Collection(\'documents\').like({\'key\': \'This is the text to search with\'}).find()`. This function can easily be served using, for example, FastAPI. (See [here](https://docs.superduperdb.com/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb) for an example.)\\n\\n## Take AI even further with SuperDuperDB on MongoDB\\n\\nAI is not just vector-search over text-documents -- there are countless additional ways in which AI can be leveraged with data. This is where SuperDuperDB excels and other solutions come up short in leveraging data in MongoDB. \\n\\nSuperDuperDB also allows developers to:\\n\\n- Search the content of [images](https://docs.superduperdb.com/docs/use_cases/items/multimodal_image_search_clip), videos and [voice memos](https://docs.superduperdb.com/docs/use_cases/items/voice_memos) in MongoDB\\n- Create [talk-to-your documents style chat applications](https://docs.superduperdb.com/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb).\\n- Use classical machine learning models [together with state-of-the-art computer vision models](https://docs.superduperdb.com/docs/use_cases/items/resnet_features). \\n\\n### Useful Links\\n\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"},{"id":"/2023/09/29/superduperdb-now-supports-cohere-and-anthropic-apis","metadata":{"permalink":"/blog/2023/09/29/superduperdb-now-supports-cohere-and-anthropic-apis","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-09-29-superduperdb-now-supports-cohere-and-anthropic-apis.md","source":"@site/blog/2023-09-29-superduperdb-now-supports-cohere-and-anthropic-apis.md","title":"SuperDuperDB now supports Cohere and Anthropic APIs","description":"We\'re happy to announce the integration of two more AI APIs, Cohere and Anthropic, into SuperDuperDB.","date":"2023-09-29T00:00:00.000Z","formattedDate":"September 29, 2023","tags":[],"readingTime":1.6,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Jumpstart AI development on MongoDB with SuperDuperDB","permalink":"/blog/2023/09/30/jump-start-ai-development"},"nextItem":{"title":"Building a Documentation Chatbot using FastAPI, React, MongoDB and SuperDuperDB","permalink":"/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb"}},"content":"*We\'re happy to announce the integration of two more AI APIs, Cohere and Anthropic, into SuperDuperDB.*\\n\\n---\\n\\n[Cohere](https://cohere.com/) and [Anthropic](https://www.anthropic.com/) provides AI developers with sorely needed alternatives to OpenAI for key AI tasks, \\nincluding:\\n\\n- text-embeddings as a service\\n- chat-completions as as service.\\n\\n\x3c!--truncate--\x3e\\n\\n## How to use the new integrations with your data\\n\\nWe\'ve posted some extensive content on how to use [OpenAI or Sentence-Transformers for encoding text as vectors](https://docs.superduperdb.com/docs/use_cases/items/compare_vector_search_solutions)\\nin your MongoDB datastore, and also [how to question-your your docs hosted in MongoDB](https://docs.superduperdb.com/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb).\\n\\nNow developers can easily use Cohere and Anthropic and drop in-replacements for the OpenAI models:\\n\\nFor **embedding text as vectors** with OpenAI developers can continue to import the functionality like this:\\n\\n```python\\nfrom superduperdb.ext.openai.model import OpenAIEmbedding\\n\\nmodel = OpenAIEmbedding(model=\'text-embedding-ada-002\')\\n```\\n\\nNow developers can **also** import Cohere\'s embedding functionality:\\n\\n```python\\nfrom superduperdb.ext.cohere.model import CohereEmbedding\\n\\nmodel = CohereEmbedding()\\n```\\n\\nSimilarly, for **chat-completion**, can continue to use OpenAI like this:\\n\\n```python\\nfrom superduperdb.ext.openai.model import OpenAIChatCompletion\\n\\nchat = OpenAIChatCompletion(\\n    prompt=\'Answer the following question clearly, concisely and accurately\',\\n    model=\'gpt-3.5-turbo\',\\n)\\n```\\n\\nNow developers can **also** import Anthropic\'s embedding functionality:\\n\\n```python\\nfrom superduperdb.ext.anthropic.model import AnthropicCompletions\\n\\nchat = AnthropicCompletions(\\n    prompt=\'Answer the following question clearly, concisely and accurately\',\\n)\\n```\\n\\n### Useful Links\\n\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"},{"id":"building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb","metadata":{"permalink":"/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-09-12-rag-question-answering.mdx","source":"@site/blog/2023-09-12-rag-question-answering.mdx","title":"Building a Documentation Chatbot using FastAPI, React, MongoDB and SuperDuperDB","description":"_Imagine effortlessly infusing AI into your data repositories\u2014databases, data warehouses, or data lakes\u2014without breaking a sweat. With SuperDuperDB, we aim to make this dream a reality.","date":"2023-09-12T00:00:00.000Z","formattedDate":"September 12, 2023","tags":[{"label":"RAG","permalink":"/blog/tags/rag"},{"label":"vector-search","permalink":"/blog/tags/vector-search"}],"readingTime":8.025,"hasTruncateMarker":true,"authors":[{"name":"Nick Byrne","title":"Founding Engineer at SuperDuperDB","url":"https://github.com/nenb","imageURL":"https://avatars.githubusercontent.com/u/55434794?v=4","key":"nenb"}],"frontMatter":{"slug":"building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb","title":"Building a Documentation Chatbot using FastAPI, React, MongoDB and SuperDuperDB","authors":["nenb"],"tags":["RAG","vector-search"]},"unlisted":false,"prevItem":{"title":"SuperDuperDB now supports Cohere and Anthropic APIs","permalink":"/blog/2023/09/29/superduperdb-now-supports-cohere-and-anthropic-apis"},"nextItem":{"title":"Enable Vector Search in MongoDB with SuperDuperDB","permalink":"/blog/introduce-vector-search-to-your-favourite-database-with-superduperdb"}},"content":"_Imagine effortlessly infusing AI into your data repositories\u2014databases, data warehouses, or data lakes\u2014without breaking a sweat. With SuperDuperDB, we aim to make this dream a reality.\\nWe want to provide everyone with the tools to build AI applications directly on top of their data stores,\\nwith just a pinch of Python magic sprinkled on top!_ \ud83d\udc0d\u2728\\n\\n_In this latest blog post we take a dive into one such example - a Retrieval Augmented Generation (RAG) app we built directly on top of our MongoDB store._\\n\\n\x3c!--truncate--\x3e\\n\\n---\\n\\nimport Bot from \'./rag-question-answering-components/Bot\';\\n\\nSince we\u2019re in the business of building open-source software, a logical in-house application of our own technology is a question-answering app, directly on our own documentation. We built this app using SuperDuperDB together with FastAPI, React and MongoDB (the \u201cFARMS\u201d stack).\\n\\nWe use retrieval augmented generation, or RAG, to integrate an existing Large Language Model (LLM) with our own data; including documents found in vector-search in an initial pass, enables using an LLM on a domain it was not trained on. SuperDuperDB allows developers to apply RAG to their own standard database, instead of insisting that users migrate a portion of their data to a vector-search database such as Pinecone, Chroma or Milvus.\\n\\nAlthough SuperDuperDB\u2019s functionality is more general than simply RAG and vector search, if a model\u2019s output does indeed consist of vectors, it\u2019s dead easy with SuperDuperDB to use these vectors downstream in vector search and RAG applications. We\u2019ll post more about the range of possibilities with SuperDuperDB in the coming weeks.\\n\\n** \ud83e\udd16 Let\'s ask the chatbot to tell us more about SuperDuperDB.**\\n\\n<Bot\\n  question=\\"What is SuperDuperDB?\\"\\n  answer=\\"SuperDuperDB is a Python package that provides tools for developers to apply AI and machine learning in their already deployed datastore. It also facilitates the setup of a scalable, open-source, and auditable environment for AI development. SuperDuperDB aims to make the integration of AI and data easier, extensible, and comprehensive. It allows for easy evaluation of model predictions and insertion back into the datastore and enables training deployment with a simple one-line command.\\"\\n/>\\n\\n### Choosing our stack\\n\\nRight out of the box, SuperDuperDB supports MongoDB, a popular NoSQL database among full-stack developers. MongoDB\'s cloud service also provides a generous free-tier offering, and and we chose this for our storage.\\n\\n** \ud83d\udea7 SuperDuperDB has experimental support for SQL databases which will be greatly expanded in the coming weeks and months!**\\n\\nWe chose FastAPI for the web framework because it creates a self-documenting server, it\u2019s extremely full-featured, and has a large community of users - and yes, because it\u2019s trendy. The FARM stack combines both MongoDB and FastAPI, and so it seemed natural to build our RAG app by adding SuperDuperDB to FARM to make FARMS!\\n\\n### Setting up the code\\n\\nWe decided to stick fairly closely to a typical FastAPI directory structure, the major difference being that we now have a new `ai/` subdirectory that contains two new modules: `artifacts.py` and `components.py`.\\n\\n```\\nbackend\\n|___ ai\\n|   |___ __init__.py\\n\u2502   |___ artifacts.py\\n|   |___ components.py\\n\u2502   |___ utils      # AI helper functions here\\n\u2502        |__ ...\\n|___ documents      # Our REST backend has a single \'documents\' route\\n|   |___ __init__.py\\n|   |___ models.py  # Pydantic models here\\n|   |___ routes.py  # AI-enhanced CRUD logic here\\n|___ __init__.py\\n|___ app.py\\n|___ config.py\\n|___ main.py\\n```\\n\\n### Artifacts\\n\\n** \ud83e\udd16 Let\'s Question The Docs to learn more about Artifacts.**\\n\\n<Bot\\n  question=\\"What is an Artifact?\\"\\n  answer=\\"An Artifact carries the necessary information and serialization method to save an object in a configured artifact store. The Artifact ensures that an object can be serialized and stored in a permanent and centralized location for future retrieval. An example of an artifact could be an image file named my_image.jpg that is saved in a configured artifact store, such as gridfs on MongoDB.\\"\\n/>\\n\\nTo build a program, you first must understand its data, and a RAG app is no different. Here, our data source are Markdown files, and we want to process them in a way which is most suitable for answering the questions we would like the LLM to answer. Here there\'s a trade-off: splitting the text into too large chunks, makes it harder to get good specificity in the vector-search step of RAG. However, splitting the docs into larger chunks, allows the LLM to use coherently ordered text to contextualize the answer it formulates.\\n\\nSuperDuperDB supports a wide range of models for prediction and training, and flexible serialization: for instance, we might use `spacy` for pre-processing labels, `torchvision` for vectorizing images and `transformers` for multi-modal retrieval. (But the program is not dependent on all these models! \u201cDon\u2019t pay for what you don\u2019t use\u201d is our motto.)\\n\\nOnce we have our artifacts, `superduperdb` takes care of the rest. All serialization, creation and tracking of metadata, and job orchestration is handled automatically: the ultimate goal is to make the development of AI applications possible for anyone. For our RAG app, this step looks roughly like the following:\\n\\n```python\\nfrom superduperdb.container.document import Document\\nfrom superduperdb.db.mongodb.query import Collection\\n...\\n\\n# `artifacts` are chunked Markdown files\\ndocuments = [Document({\\"KEY\\": v}) for v in artifacts]\\ndb.execute(Collection(name=\\"NAME\\").insert_many(documents))\\n```\\n\\n### Components\\n\\n** \ud83e\udd16 QtD again!**\\n\\n<Bot\\n  question=\\"Give examples of Components.\\"\\n  answer=\\"SuperDuperDB has several components that work together to provide a unified user experience for the programmer. The DB component handles the underlying datastore and provides the functionality for storing and retrieving data. It is the core component of SuperDuperDB. The Models component defines the structure and behavior of the data to be stored in the DB. It includes classes or structures that represent different types of data and their relationships. The Encoders component is responsible for encoding and decoding data between different formats. It allows data to be transformed into a compatible format for storage in the DB. These are only some of the components that are provided by SuperDuperDB.\\"\\n/>\\n\\nWe are only going to use that first feature, and install our AI models inside our database.\\n\\n** \ud83d\udca1 But Components can also listen for specific events before performing an action, track statistics of database artifacts over time and even train models.**\\n\\nWe chose `text-embedding-ada-002` for our text embedding model, which we compute on the app\'s own server. For the chatbot, we selected the well-known `gpt-3.5-turbo`; now we can start talking to our chatbot!\\n\\n### Querying the database\\n\\nOur app is a particularly simple example of a CRUD app without the UPDATE or DELETE actions: once we have created our artifacts, we just have to READ the database for the text most similar to our question.\\n\\n### Building queries\\n\\nUsing SuperDuperDB to build a query to search for relevant text snippets is very similar to using a standard MongoDB driver such as `pymongo`, but with additional keyword arguments like n in this example, which says how many similar items to return from the database.\\n\\n```python\\nfrom superduperdb.db.mongodb.query import Collection\\n\\ncontext = (\\n    Collection(name=\\"NAME\\")\\n    .like(\\n        {\\"KEY\\": query},  # Example: \'What is SuperDuperDB?\'\\n        n=5,\\n        vector_index=\\"NAME2\\",\\n    )\\n    .find()\\n)\\n```\\n\\n### Dispatching QA queries\\n\\nUnder the hood, SuperDuperDB can be configured to perform searches and comparisons using a vector database like the open-source LanceDB, or MongoDB Atlas, which is what we used in QtD.\\n\\nExecuting a query is also very similar to a standard CRUD application, except that the database needs to be wrapped in a SuperDuperDB after it is created:\\n\\n```python\\nfrom pymongo import MongoClient\\n\\nfrom superduperdb import superduper\\n\\nMONGO_URI = ...\\n\\nmongo_db = MongoClient(MONGO_URI)\\ndb = superduper(mongo_db)  # It\'s now a super duper database!\\n\\ndb.execute(context)  # proceed as normal\\n```\\n\\n### Summary\\n\\nThe FARM stack works well with SuperDuperDB in Python to build RAG applications.\\n\\nSuperDuperDB\u2019s support for vector search allows developers to minimize the problems with LLM hallucinations, as well as extending LLM coverage to domains the LLM was not trained on.\\n\\nMany RAG and question-answering applications use `langchain`, but SuperDuperDB stands out with its lightweight third-party integrations, support for \u201cbring your own model\u201d, and greater scope, incorporating scalable inference and training directly in your database.\\n\\n### SuperDuperDB into the future!\\n\\n** \ud83e\udd16 Let\'s see if the bot can help us decide what to do next.**\\n\\n<Bot\\n  question=\\"What is SuperDuperDB\'s mission?\\"\\n  answer=\\"SuperDuperDB\'s mission is to facilitate and accelerate the developer journey between data and AI models by creating an easy-to-use, extensible, and comprehensive Python framework for integrating AI and ML directly to the datastore. They aim to empower developers, data scientists, and architects to leverage the open-source ecosystem in their datastore deployments. They also aim to enable scalability and industrial scale deployment, provide easy-to-use tools for individual developers, allow continued use of already existing or deployed datastores without data migration, follow a fully open-source approach, and enable individuals and organizations to circumvent vendor lock-in strategies.\\"\\n/>\\n\\nThanks for reading! If you have any questions about this article, or SuperDuperDB in general, please don\u2019t hesitate to contact us at opensource@superduperdb.com.\\n\\n### Useful Links\\n\\n- **[Question the docs online](https://www.qtd.superduperdb.com/)!**\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"},{"id":"introduce-vector-search-to-your-favourite-database-with-superduperdb","metadata":{"permalink":"/blog/introduce-vector-search-to-your-favourite-database-with-superduperdb","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-09-09-vector-search.mdx","source":"@site/blog/2023-09-09-vector-search.mdx","title":"Enable Vector Search in MongoDB with SuperDuperDB","description":"_In this blog-post we show you how to easily operate vector-search in MongoDB","date":"2023-09-09T00:00:00.000Z","formattedDate":"September 9, 2023","tags":[{"label":"AI","permalink":"/blog/tags/ai"},{"label":"vector-search","permalink":"/blog/tags/vector-search"}],"readingTime":5.665,"hasTruncateMarker":true,"authors":[{"name":"Duncan Blythe","title":"CTO & Co-founder of SuperDuperDB","url":"https://github.com/blythed","imageURL":"https://avatars.githubusercontent.com/u/15139331?v=4","key":"blythed"}],"frontMatter":{"slug":"introduce-vector-search-to-your-favourite-database-with-superduperdb","title":"Enable Vector Search in MongoDB with SuperDuperDB","authors":["blythed"],"tags":["AI","vector-search"]},"unlisted":false,"prevItem":{"title":"Building a Documentation Chatbot using FastAPI, React, MongoDB and SuperDuperDB","permalink":"/blog/building-a-documentation-chatbot-using-fastapi-react-mongodb-and-superduperdb"},"nextItem":{"title":"Introducing SuperDuperDB: Bringing AI to your Datastore in Python","permalink":"/blog/bringing-ai-to-your-datastore-in-python"}},"content":"_In this blog-post we show you how to easily operate vector-search in MongoDB\\nAtlas using SuperDuperDB, leading to many savings and efficiencies in\\nyour AI development._\\n\\n---\\n\\nIn 2023 vector-databases are hugely popular; they provide the opportunity for developers to connect LLMs, such as OpenAI\u2019s GPT models, with their data, as well as providing the key to deploying \u201csearch-by-meaning\u201d on troves of documents.\\n\\n\x3c!--truncate--\x3e\\n\\nHowever: a key unanswered question, for which there is no widely accepted answer, is:\\n\\n:::info\\nHow do the vectors in my vector-database get there in the first place?\\n:::\\n\\nVectors (arrays of numbers used in vector-search) differ from the content of most databases, since they need to be calculated on the basis of other data.\\n\\nCurrently there are 2 approaches:\\n\\n## Possibility 1: models live together with the database to create vectors at insertion time\\n\\nWhen data is inserted into a vector-database, the database may be configured to \u201ccalculate\u201d or \u201ccompute\u201d vectors on the basis of this data (generally text). This means that the database environment also has access to some compute and AI models, or access to APIs such as OpenAI, in order to obtain vectors.\\n\\nExamples of this approach are:\\n\\n- _Weaviate_ (support for a range of pre-defined models, some support for bringing own model)\\n- _Chroma_ (support for OpenAI and sentence_transformers)\\n\\n**Pros**:\\n\\n- The data and compute live together, so developers don\u2019t need to create an additional app in order to use the vector-database\\n\\n**Cons**:\\n\\n- Developers are limited by the models available in the vector-database and the compute resources on the vector-database server\\n- Primary data needs to be stored in the vector-database; classic-database + external vector-search isn\u2019t an expected pattern.\\n- Training of models is generally not supported.\\n\\n## Possibility 2: the vector-database requires developers to provide their own vectors with their own models\\n\\nIn this approach, developers are required to build an app which deploys model computations over data which is extracted from the datastore.\\n\\nExamples of this approach are:\\n\\n- _LanceDB_\\n- _Milvus_\\n\\n**Pros**:\\n\\n- By developing a vector-computation app, the user can use the full flexibility of the open-source landscape for computing these vectors, and can architect compute resources independently from vector-database resources\\n- The vector-database \u201cspecializes\u201d in vector-search and storage of vectors, giving better performance guarantees as a result\\n\\n**Cons**:\\n\\n- Huge overhead of building one\u2019s own computation app.\\n- All communication between app, vector-database and datastore (if using external datastore) must be managed by the developer\\n\\n### Enter SuperDuperDB\\n\\n:::info\\nSuperDuperDB is a middle path to scalability, flexiblity and ease-of-use in vector-search and far beyond.\\n:::\\n\\n- SuperDuperDB is an open-source Python environment which wraps databases and AI models with additional functionality to make them \u201cready\u201d to interface with one-another; developers are able to host their data in a \u201cclassical\u201d database, but use this database as a vector-database.\\n- SuperDuperDB allows users to integrate any model from the Python open source ecosystem (torch, sklearn, transformers, sentence_transformers as well as OpenAI\u2019s API), with their datastore. It uses a flexible scheme, allowing new frameworks and code-bases to be integrated without requiring the developer to add additional classes or functionality.\\n- SuperDuperDB can be co-located with the database in infrastructure, but at the same time has access to its own compute, which is scalable. This makes it vertically performant and at the same time, ready to scale horizontally to accommodate larger usage.\\n- SuperDuperDB enables training directly with the datastore: developers are only required to specify a database-query to initiate training on scalable compute.\\n- Developers are not required to program tricky boilerplate code or architectures for computing vector outputs and storing these back in the database. This is all supported natively by SuperDuperDB.\\n- SuperDuperDB supports data of arbitrary type: with its flexible serialization model, SuperDuperDB can handle text, images, tensors, audio and beyond.\\n- SuperDuperDB\u2019s scope goes far beyond vector-search; it supports models with arbitrary outputs: classification, generative AI, fore-casting and much more are all within scope and supported. This allows users to build interdependent models, where base models feed their outputs into downstream models; this enables transfer learning, and quality assurance via classification on generated outputs, to name but 2 key outcomes of SuperDuperDB\u2019s integration model.\\n\\n### Minimal boilerplate to connect to SuperDuperDB\\n\\nConnecting to MongoDB with SuperDuperDB is super easy. The connection may be used to insert documents, although insertion/ ingestion can also proceed via other sources/ client libraries.\\n\\n```python\\nimport json\\nimport pymongo\\n\\nfrom superduperdb import superduper\\nfrom superduperdb.container.document import Document\\nfrom superduperdb.db.mongodb.query import Collection\\n\\ndb = pymongo.MongoClient().documents\\ndb = superduper(db)\\n\\ncollection = Collection(\'wikipedia\')\\n\\nwith open(\'wikipedia.json\') as f:\\n    data = json.load(f)\\n\\ndb.execute(\\n    collection.insert_many([Document(r) for r in data])\\n)\\n```\\n\\n### Set up vector-search with SuperDuperDB in one command!\\n\\nimport Tabs from \'@theme/Tabs\';\\nimport TabItem from \'@theme/TabItem\';\\n\\n```mdx-code-block\\n<Tabs>\\n<TabItem value=\\"openai\\" label=\\"OpenAI\\">\\n```\\n\\n```python\\nfrom superduperdb.container.vector_index import VectorIndex\\nfrom superduperdb.container.listener import Listener\\nfrom superduperdb.ext.numpy.array import array\\nfrom superduperdb.ext.openai import OpenAIEmbedding\\n\\ndb.add(\\n    VectorIndex(\\n        identifier=f\'wiki-index-openai\',\\n        indexing_listener=Listener(\\n            model=OpenAIEmbedding(model=\'text-embedding-ada-002\'),\\n            key=\'abstract\',\\n            select=collection.find(),\\n            predict_kwargs={\'max_chunk_size\': 1000},\\n        )\\n    )\\n)\\n```\\n\\n```mdx-code-block\\n</TabItem>\\n<TabItem value=\\"st\\" label=\\"Sentence Transformers\\">\\n```\\n\\n```python\\nfrom superduperdb.container.vector_index import VectorIndex\\nfrom superduperdb.container.listener import Listener\\nfrom superduperdb.ext.numpy.array import array\\nfrom sentence_transformers import Pipeline\\n\\nmodel = Model(\\n    identifier=\'all-MiniLM-L6-v2\',\\n    object=sentence_transformers.SentenceTransformer(\'all-MiniLM-L6-v2\'),\\n    encoder=array(\'float32\', shape=(384,)),\\n    predict_method=\'encode\',\\n    batch_predict=True,\\n)\\n\\ndb.add(\\n    VectorIndex(\\n        identifier=f\'wiki-index-sentence-transformers\',\\n        indexing_listener=Listener(\\n            model=model,\\n            key=\'abstract\',\\n            select=collection.find(),\\n            predict_kwargs={\'max_chunk_size\': 1000},\\n        )\\n    )\\n)\\n```\\n\\n```mdx-code-block\\n</TabItem>\\n</Tabs>\\n```\\n\\nThis approach is simple enough to allow models from a vast range of libraries and sources to be implemented: open/ closed source, self-built or library based and much more.\\n\\nNow that the index has been created, queries may be dispatched in a new session to SuperDuperDB without reloading the model:\\n\\n```python\\ncur = db.execute(\\n    collection\\n        .like({\'title\': \'articles about sport\'}, n=10, vector_index=f\'wiki-index\')\\n        .find({}, {\'title\': 1})\\n)\\n\\nfor r in cur:\\n    print(r)\\n```\\n\\nThe great thing about using MongoDB or a similar battle tested database for vector-search, is that it can be easily combined with important filtering approaches. In this query, we restrict the results to a hard match involving the word \u201cAustralia\u201d:\\n\\n```python\\ncur = db.execute(\\n    collection\\n        .like({\'title\': \'articles about sport\'}, n=100, vector_index=f\'wiki-index-{model.identifier}\')\\n        .find({\'title\': {\'$regex\': \'.*Australia\'}})\\n)\\n\\nfor r in cur:\\n    print(r[\'title\'])\\n```\\n\\n### Useful Links\\n\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"},{"id":"bringing-ai-to-your-datastore-in-python","metadata":{"permalink":"/blog/bringing-ai-to-your-datastore-in-python","editUrl":"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/blog/2023-09-08-introducing.md","source":"@site/blog/2023-09-08-introducing.md","title":"Introducing SuperDuperDB: Bringing AI to your Datastore in Python","description":"It\'s 2023, and unless you\'ve been in cryo-sleep since mid-2022, you\'ll have heard about the explosion of powerful AI and LLMs. Leveraging these LLMs, developers are now able to connect existing data with AI using vector search.","date":"2023-09-08T00:00:00.000Z","formattedDate":"September 8, 2023","tags":[{"label":"AI","permalink":"/blog/tags/ai"},{"label":"data-store","permalink":"/blog/tags/data-store"},{"label":"Python","permalink":"/blog/tags/python"}],"readingTime":3.905,"hasTruncateMarker":true,"authors":[{"name":"Duncan Blythe","title":"CTO & Co-founder of SuperDuperDB","url":"https://github.com/blythed","imageURL":"https://avatars.githubusercontent.com/u/15139331?v=4","key":"blythed"}],"frontMatter":{"slug":"bringing-ai-to-your-datastore-in-python","title":"Introducing SuperDuperDB: Bringing AI to your Datastore in Python","authors":["blythed"],"tags":["AI","data-store","Python"]},"unlisted":false,"prevItem":{"title":"Enable Vector Search in MongoDB with SuperDuperDB","permalink":"/blog/introduce-vector-search-to-your-favourite-database-with-superduperdb"}},"content":"It\'s 2023, and unless you\'ve been in cryo-sleep since mid-2022, you\'ll have heard about the explosion of powerful AI and LLMs. Leveraging these LLMs, developers are now able to connect existing data with AI using vector search.\\n\\n\x3c!--truncate--\x3e\\n\\nAI models can allow users to extract valuable information out of their existing data stores (databases, data lakes, data warehouses), in a host of different ways: semantic search, retrieval augmented generation, visual classification, conditional image generation, recommendation systems, anomaly and fraud detection, image search, multimodal search, time-series analysis and much, much more.\\n\\nIn the AI-powered future, a full-featured data application will have five parts:\\n\\n- Backend\\n- Frontend\\n- Data store\\n- AI models\\n- Vector search\\n\\nThere are many different solutions for AI model computations and vector search separately, but some deep pitfalls appear when you put both together.\\n\\n### A model has no natural way to talk to a datastore\\n\\nThe most flexible frameworks for building AI models, like PyTorch, don\u2019t understand text or images out-of-the-box without writing custom code.\\n\\nModel libraries containing precompiled and trained AI models often support text but not computer vision or audio classification. Worse, you can\u2019t just pass a data store connection to such a library, and tell the library to use the connection to train the model: you have to write more custom code.\\n\\nThere is no general Python abstraction bringing self-built models like PyTorch, models imported from libraries like Scikit-Learn, and models hosted behind APIs like OpenAI, together under one roof with existing data stores: even more custom code.\\n\\nThe result is that developers still must perform considerable coding to connect AI models with their data stores.\\n\\n### Vector databases mean data fragmentation and difficulties with data-lineage\\n\\nA vector database is powerful but leaves architects and developers with questions:\\n\\n- Should all data now live in the vector database?\\n- Should the vector database only contain vectors?\\n\\nIdeally, data would stay in the primary datastore, but many datastores do not have a vector search implementation.\\n\\nOn the other hand, it is problematic to make the vector database the primary datastore for an application, as most vector databases lack the specialized features of classical relational databases or document stores, and offer few consistency or performance guarantees.\\n\\n### Connect models and datastores with SuperDuperDB\\n\\n- SuperDuperDB is a framework which wraps data stores and AI models, with minimal boilerplate code.\\n- Arbitrary models from open-source are applied directly to datastore queries and the outputs can be saved right back in the datastore, keeping everything in one location. Computations scale using the rich and diverse tools in the PyData ecosystem.\\n- SuperDuperDB allows complex data types as inputs to AI models, such as images, audio and beyond.\\n- SuperDuperDB can instantly make a classical database or data store vector-searchable. SuperDuperDB wraps well-known query APIs with additional commands for vector search, and takes care of organizing the results into a consistent result set for databases without a native vector-search implementation.\\n- SuperDuperDB can use a query to train models directly on the data store. The fully open-source SuperDuperDB environment provides a scalable and serverless developer experience for model training.\\n\\n### Get started easily, and go far\\n\\nSuperDuperDB is designed to make it as simple as possible to get started. For example, to connect with SuperDuperDB using MongoDB and Python, just type:\\n\\n```python\\nfrom superduperdb import superduper\\nfrom pymongo import MongoClient\\n\\ndb = MongoClient().my_database\\ndb = superduper(db)\\n```\\n\\nAt the same time, SuperDuperDB is ready for the full range of modern AI tools. It scales horizontally and includes a flexible approach allowing arbitrary AI frameworks to be used together, including torch, transformers, sklearn and openai.\\n\\n- GitHub: https://github.com/SuperDuperDB/superduperdb\\n- Docs: https://docs.superduperdb.com\\n- Blog: https://www.superduperdb.com/blog\\n\\n### The road ahead\\n\\nIn the weeks and months to come we\u2019ll be:\\n\\n- Adding SQL support (already close to completion)\\n- Building bridges to more AI frameworks, libraries, models and API services\\n- Creating tools to manage a SuperDuperDB deployment in production\\n\\n### Useful Links\\n\\n- **[Website](https://superduperdb.com/)**\\n- **[GitHub](https://github.com/SuperDuperDB/superduperdb)**\\n- **[Documentation](https://docs.superduperdb.com/docs/category/get-started)**\\n- **[Blog](https://docs.superduperdb.com/blog)**\\n- **[Example Use Cases & Apps](https://docs.superduperdb.com/docs/category/use-cases)**\\n- **[Slack Community](https://join.slack.com/t/superduperdb/shared_invite/zt-1zuojj0k0-RjAYBs1TDsvEa7yaFGa6QA)**\\n- **[LinkedIn](https://www.linkedin.com/company/superduperdb/)**\\n- **[Twitter](https://twitter.com/superduperdb)**\\n- **[Youtube](https://www.youtube.com/@superduperdb)**\\n\\n### Contributors are welcome!\\n\\nSuperDuperDB is open-source and permissively licensed under the [Apache 2.0 license](https://github.com/SuperDuperDB/superduperdb/blob/main/LICENSE). We would like to encourage developers interested in open-source development to contribute in our discussion forums, issue boards and by making their own pull requests. We\'ll see you on [GitHub](https://github.com/SuperDuperDB/superduperdb)!\\n\\n### Become a Design Partner!\\n\\nWe are looking for visionary organizations which we can help to identify and implement transformative AI applications for their business and products. We\'re offering this absolutely for free. If you would like to learn more about this opportunity please reach out to us via email: partnerships@superduperdb.com"}]}')}}]);