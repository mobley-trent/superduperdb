"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"useCasesSidebar":[{"type":"category","label":"Vector search","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"Building a Vanilla Text Vector-Search on MongoDB","href":"/docs/use_cases/vector_search/plain_vector_search","docId":"use_cases/vector_search/plain_vector_search","unlisted":false},{"type":"link","label":"Building a Multimodal Vector-Search Using CLIP on MongoDB","href":"/docs/use_cases/vector_search/multimodal_image_search_clip","docId":"use_cases/vector_search/multimodal_image_search_clip","unlisted":false},{"type":"link","label":"Build in Video Vector-Search with Text on MongoDB","href":"/docs/use_cases/vector_search/video_search","docId":"use_cases/vector_search/video_search","unlisted":false},{"type":"link","label":"Building a Vector-Search Using Chunked Data on MongoDB","href":"/docs/use_cases/vector_search/chunked_vector_search","docId":"use_cases/vector_search/chunked_vector_search","unlisted":false}],"href":"/docs/category/vector-search"},{"type":"category","label":"SQL examples","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"Building a Multimodel Vector-Search on DuckDB","href":"/docs/use_cases/sql_examples/multi-modal-duckdb","docId":"use_cases/sql_examples/multi-modal-duckdb","unlisted":false},{"type":"link","label":"Building a Vector-Search on Snowflake","href":"/docs/use_cases/sql_examples/snowflake-example","docId":"use_cases/sql_examples/snowflake-example","unlisted":false}],"href":"/docs/category/sql-examples"},{"type":"category","label":"Question answering","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"Building Q&A Assistant Using OpenAI on MongoDB","href":"/docs/use_cases/question-answering/Chatbot","docId":"use_cases/question-answering/Chatbot","unlisted":false},{"type":"link","label":"Chatting with your SnowFlakes Database Using OpenAI","href":"/docs/use_cases/question-answering/chat_with_your_database","docId":"use_cases/question-answering/chat_with_your_database","unlisted":false},{"type":"link","label":"Building Voice-Memo Assistant on MongoDB","href":"/docs/use_cases/question-answering/voice_memos","docId":"use_cases/question-answering/voice_memos","unlisted":false}],"href":"/docs/category/question-answering"},{"type":"category","label":"Classical ML","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"Training and Managing MNIST Predictions on MongoDB","href":"/docs/use_cases/classical_tasks/mnist_torch","docId":"use_cases/classical_tasks/mnist_torch","unlisted":false},{"type":"link","label":"Building an Image Feature-Store Using Torchvision on MongoDB","href":"/docs/use_cases/classical_tasks/resnet_features","docId":"use_cases/classical_tasks/resnet_features","unlisted":false},{"type":"link","label":"Building Sentiment Analyser Using transformers on MongoDB","href":"/docs/use_cases/classical_tasks/sentiment_analysis_use_case","docId":"use_cases/classical_tasks/sentiment_analysis_use_case","unlisted":false},{"type":"link","label":"Transfer-Learning Using Transformers and Scikit-Learn on MongoDB","href":"/docs/use_cases/classical_tasks/transfer_learning","docId":"use_cases/classical_tasks/transfer_learning","unlisted":false}],"href":"/docs/category/classical-ml"},{"type":"category","label":"Productionization","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"SuperDuperDB: cluster usage","href":"/docs/use_cases/productionization/sandbox-example","docId":"use_cases/productionization/sandbox-example","unlisted":false}],"href":"/docs/category/productionization"}],"tutorialSidebar":[{"type":"link","label":"Welcome","href":"/docs/docs/intro","docId":"docs/intro","unlisted":false},{"type":"link","label":"FAQ","href":"/docs/docs/faq","docId":"docs/faq","unlisted":false},{"type":"category","label":"Get started","collapsed":true,"collapsible":true,"items":[{"type":"link","label":"Quickstart","href":"/docs/docs/get_started/quickstart","docId":"docs/get_started/quickstart","unlisted":false},{"type":"link","label":"Installation","href":"/docs/docs/get_started/installation","docId":"docs/get_started/installation","unlisted":false},{"type":"link","label":"Minimum working example","href":"/docs/docs/get_started/minimum_working_example","docId":"docs/get_started/minimum_working_example","unlisted":false}],"href":"/docs/category/get-started"},{"type":"category","label":"Setup","collapsed":true,"collapsible":true,"items":[{"type":"link","label":"Configure","href":"/docs/docs/setup/configuration","docId":"docs/setup/configuration","unlisted":false},{"type":"link","label":"Sandbox","href":"/docs/docs/setup/sandbox","docId":"docs/setup/sandbox","unlisted":false},{"type":"link","label":"Testing","href":"/docs/docs/setup/testing","docId":"docs/setup/testing","unlisted":false},{"type":"link","label":"System Observability","href":"/docs/docs/setup/observability","docId":"docs/setup/observability","unlisted":false}],"href":"/docs/category/setup"},{"type":"category","label":"Data integrations","items":[{"type":"link","label":"MongoDB","href":"/docs/docs/data_integrations/mongodb","docId":"docs/data_integrations/mongodb","unlisted":false},{"type":"category","label":"SQL Databases","items":[{"type":"link","label":"MySQL","href":"/docs/docs/data_integrations/mysql","docId":"docs/data_integrations/mysql","unlisted":false},{"type":"link","label":"PostgreSQL","href":"/docs/docs/data_integrations/postgresql","docId":"docs/data_integrations/postgresql","unlisted":false},{"type":"link","label":"Snowflake","href":"/docs/docs/data_integrations/snowflake","docId":"docs/data_integrations/snowflake","unlisted":false},{"type":"link","label":"SQLite","href":"/docs/docs/data_integrations/sqlite","docId":"docs/data_integrations/sqlite","unlisted":false},{"type":"link","label":"DuckDB","href":"/docs/docs/data_integrations/duckdb","docId":"docs/data_integrations/duckdb","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/docs/data_integrations/sql"},{"type":"link","label":"Pandas","href":"/docs/docs/data_integrations/pandas","docId":"docs/data_integrations/pandas","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/data-integrations"},{"type":"category","label":"AI integrations","items":[{"type":"link","label":"Anthropic","href":"/docs/docs/ai_integrations/anthropic","docId":"docs/ai_integrations/anthropic","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/docs/ai_integrations/cohere","docId":"docs/ai_integrations/cohere","unlisted":false},{"type":"link","label":"Custom Models","href":"/docs/docs/ai_integrations/custom","docId":"docs/ai_integrations/custom","unlisted":false},{"type":"link","label":"Jina","href":"/docs/docs/ai_integrations/jina","docId":"docs/ai_integrations/jina","unlisted":false},{"type":"link","label":"LLMs","href":"/docs/docs/ai_integrations/llm","docId":"docs/ai_integrations/llm","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/docs/ai_integrations/openai","docId":"docs/ai_integrations/openai","unlisted":false},{"type":"link","label":"PyTorch","href":"/docs/docs/ai_integrations/pytorch","docId":"docs/ai_integrations/pytorch","unlisted":false},{"type":"link","label":"Scikit-learn","href":"/docs/docs/ai_integrations/sklearn","docId":"docs/ai_integrations/sklearn","unlisted":false},{"type":"link","label":"Transformers","href":"/docs/docs/ai_integrations/transformers","docId":"docs/ai_integrations/transformers","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/ai-integrations"},{"type":"category","label":"Fundamentals","items":[{"type":"link","label":"Design","href":"/docs/docs/fundamentals/design","docId":"docs/fundamentals/design","unlisted":false},{"type":"link","label":"Datalayer","href":"/docs/docs/fundamentals/datalayer_overview","docId":"docs/fundamentals/datalayer_overview","unlisted":false},{"type":"category","label":"Components","items":[{"type":"link","label":"Encoding data","href":"/docs/docs/fundamentals/document_encoder_abstraction","docId":"docs/fundamentals/document_encoder_abstraction","unlisted":false},{"type":"link","label":"Predictors and Models","href":"/docs/docs/fundamentals/predictors_and_models","docId":"docs/fundamentals/predictors_and_models","unlisted":false},{"type":"link","label":"Procedural and Declarative API","href":"/docs/docs/fundamentals/procedural_vs_declarative_api","docId":"docs/fundamentals/procedural_vs_declarative_api","unlisted":false},{"type":"link","label":"Component versioning","href":"/docs/docs/fundamentals/component_versioning","docId":"docs/fundamentals/component_versioning","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/docs/fundamentals/component_abstraction"},{"type":"link","label":"Vector-search","href":"/docs/docs/fundamentals/vector_search_algorithm","docId":"docs/fundamentals/vector_search_algorithm","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/docs/fundamentals/glossary"},{"type":"category","label":"How To","items":[{"type":"link","label":"Connecting to the Database","href":"/docs/docs/setup/connecting","docId":"docs/setup/connecting","unlisted":false},{"type":"link","label":"Setting up tables and encodings","href":"/docs/docs/walkthrough/data_encodings_and_schemas","docId":"docs/walkthrough/data_encodings_and_schemas","unlisted":false},{"type":"link","label":"Inserting data","href":"/docs/docs/walkthrough/inserting_data","docId":"docs/walkthrough/inserting_data","unlisted":false},{"type":"link","label":"Working with external data sources","href":"/docs/docs/walkthrough/referring_to_data_from_diverse_sources","docId":"docs/walkthrough/referring_to_data_from_diverse_sources","unlisted":false},{"type":"link","label":"Working with and inserting large pieces of data","href":"/docs/docs/walkthrough/using_hybrid_storage_to_handle_large_data_blobs","docId":"docs/walkthrough/using_hybrid_storage_to_handle_large_data_blobs","unlisted":false},{"type":"link","label":"Selecting data","href":"/docs/docs/walkthrough/selecting_data","docId":"docs/walkthrough/selecting_data","unlisted":false},{"type":"link","label":"Adding Models to the Database","href":"/docs/docs/walkthrough/ai_models","docId":"docs/walkthrough/ai_models","unlisted":false},{"type":"link","label":"Training models directly on your datastore","href":"/docs/docs/walkthrough/training_models","docId":"docs/walkthrough/training_models","unlisted":false},{"type":"link","label":"Applying the models","href":"/docs/docs/walkthrough/apply_models","docId":"docs/walkthrough/apply_models","unlisted":false},{"type":"link","label":"Configuring models to ingest features from other models","href":"/docs/docs/walkthrough/linking_interdependent_models","docId":"docs/walkthrough/linking_interdependent_models","unlisted":false},{"type":"link","label":"Setting up and accessing vector-search","href":"/docs/docs/walkthrough/vector_search","docId":"docs/walkthrough/vector_search","unlisted":false},{"type":"link","label":"Serializing components with SuperDuperDB","href":"/docs/docs/walkthrough/serialization","docId":"docs/walkthrough/serialization","unlisted":false},{"type":"link","label":"Creating complex stacks of functionality","href":"/docs/docs/walkthrough/creating_stacks_of_functionality","docId":"docs/walkthrough/creating_stacks_of_functionality","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/docs/walkthrough/tutorial_walkthrough"},{"type":"category","label":"Production features","items":[{"type":"link","label":"Developer vs. production mode","href":"/docs/docs/production/developer_vs_production_mode","docId":"docs/production/developer_vs_production_mode","unlisted":false},{"type":"link","label":"Command line interface","href":"/docs/docs/production/command_line_interface","docId":"docs/production/command_line_interface","unlisted":false},{"type":"link","label":"Running non-blocking dask computations in the background","href":"/docs/docs/production/non_blocking_dask_jobs","docId":"docs/production/non_blocking_dask_jobs","unlisted":false},{"type":"link","label":"Setting up SuperDuperDB as a change-data-capture daemon","href":"/docs/docs/production/change_data_capture","docId":"docs/production/change_data_capture","unlisted":false},{"type":"link","label":"Vector-searcher service","href":"/docs/docs/production/vector_comparison_service","docId":"docs/production/vector_comparison_service","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Use cases","collapsed":true,"collapsible":true,"items":[{"type":"category","label":"Vector Search","items":[{"type":"link","label":"Building a Vanilla Text Vector-Search on MongoDB","href":"/docs/use_cases/vector_search/plain_vector_search","docId":"use_cases/vector_search/plain_vector_search","unlisted":false},{"type":"link","label":"Building a Multimodal Vector-Search Using CLIP on MongoDB","href":"/docs/use_cases/vector_search/multimodal_image_search_clip","docId":"use_cases/vector_search/multimodal_image_search_clip","unlisted":false},{"type":"link","label":"Build in Video Vector-Search with Text on MongoDB","href":"/docs/use_cases/vector_search/video_search","docId":"use_cases/vector_search/video_search","unlisted":false},{"type":"link","label":"Building a Vector-Search Using Chunked Data on MongoDB","href":"/docs/use_cases/vector_search/chunked_vector_search","docId":"use_cases/vector_search/chunked_vector_search","unlisted":false},{"type":"link","label":"Building a Multimodel Vector-Search on DuckDB","href":"/docs/use_cases/sql_examples/multi-modal-duckdb","docId":"use_cases/sql_examples/multi-modal-duckdb","unlisted":false},{"type":"link","label":"Building a Vector-Search on Snowflake","href":"/docs/use_cases/sql_examples/snowflake-example","docId":"use_cases/sql_examples/snowflake-example","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/vector-search-1"},{"type":"category","label":"Question Answering","items":[{"type":"link","label":"Building Q&A Assistant Using OpenAI on MongoDB","href":"/docs/use_cases/question-answering/Chatbot","docId":"use_cases/question-answering/Chatbot","unlisted":false},{"type":"link","label":"Chatting with your SnowFlakes Database Using OpenAI","href":"/docs/use_cases/question-answering/chat_with_your_database","docId":"use_cases/question-answering/chat_with_your_database","unlisted":false},{"type":"link","label":"Building Voice-Memo Assistant on MongoDB","href":"/docs/use_cases/question-answering/voice_memos","docId":"use_cases/question-answering/voice_memos","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/question-answering-1"},{"type":"category","label":"Classical ML Applications","items":[{"type":"link","label":"Training and Managing MNIST Predictions on MongoDB","href":"/docs/use_cases/classical_tasks/mnist_torch","docId":"use_cases/classical_tasks/mnist_torch","unlisted":false},{"type":"link","label":"Building an Image Feature-Store Using Torchvision on MongoDB","href":"/docs/use_cases/classical_tasks/resnet_features","docId":"use_cases/classical_tasks/resnet_features","unlisted":false},{"type":"link","label":"Building Sentiment Analyser Using transformers on MongoDB","href":"/docs/use_cases/classical_tasks/sentiment_analysis_use_case","docId":"use_cases/classical_tasks/sentiment_analysis_use_case","unlisted":false},{"type":"link","label":"Transfer-Learning Using Transformers and Scikit-Learn on MongoDB","href":"/docs/use_cases/classical_tasks/transfer_learning","docId":"use_cases/classical_tasks/transfer_learning","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/classical-ml-applications"},{"type":"category","label":"Productionization","items":[{"type":"link","label":"SuperDuperDB: cluster usage","href":"/docs/use_cases/productionization/sandbox-example","docId":"use_cases/productionization/sandbox-example","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/productionization-1"}],"href":"/docs/category/use-cases"},{"type":"category","label":"Reference","items":[{"type":"link","label":"API Reference","href":"https://docs.superduperdb.com/apidocs/source/superduperdb.html"},{"type":"link","label":"Change log","href":"https://raw.githubusercontent.com/SuperDuperDB/superduperdb/main/CHANGELOG.md"}],"collapsed":true,"collapsible":true}]},"docs":{"docs/ai_integrations/anthropic":{"id":"docs/ai_integrations/anthropic","title":"Anthropic","description":"superduperdb allows users to work with anthropic API models.","sidebar":"tutorialSidebar"},"docs/ai_integrations/cohere":{"id":"docs/ai_integrations/cohere","title":"Cohere","description":"superduperdb allows users to work with cohere API models.","sidebar":"tutorialSidebar"},"docs/ai_integrations/custom":{"id":"docs/ai_integrations/custom","title":"Custom Models","description":"superduperdb provides fully flexible support for AI models from across the","sidebar":"tutorialSidebar"},"docs/ai_integrations/jina":{"id":"docs/ai_integrations/jina","title":"Jina","description":"superduperdb allows users to work with Jina Embeddings models through the Jina Embedding API.","sidebar":"tutorialSidebar"},"docs/ai_integrations/llm":{"id":"docs/ai_integrations/llm","title":"LLMs","description":"superduperdb allows users to work with LLM services and models","sidebar":"tutorialSidebar"},"docs/ai_integrations/openai":{"id":"docs/ai_integrations/openai","title":"OpenAI","description":"superduperdb allows users to work with openai API models.","sidebar":"tutorialSidebar"},"docs/ai_integrations/pytorch":{"id":"docs/ai_integrations/pytorch","title":"PyTorch","description":"superduperdb allows users to work with arbitrary torch models, with custom pre-, post-processing and input/ output data-types.","sidebar":"tutorialSidebar"},"docs/ai_integrations/sklearn":{"id":"docs/ai_integrations/sklearn","title":"Scikit-learn","description":"superduperdb allows users to work with arbitrary sklearn estimators, with additional support for pre-, post-processing and input/ output data-types.","sidebar":"tutorialSidebar"},"docs/ai_integrations/supported_ai_frameworks":{"id":"docs/ai_integrations/supported_ai_frameworks","title":"Community Support","description":"The primary way in which developers will integrate and implement functionality from popular AI frameworks, is via"},"docs/ai_integrations/transformers":{"id":"docs/ai_integrations/transformers","title":"Transformers","description":"superduperdb allows users to work with arbitrary transformers pipelines, with custom input/ output data-types.","sidebar":"tutorialSidebar"},"docs/data_integrations/duckdb":{"id":"docs/data_integrations/duckdb","title":"DuckDB","description":"Connecting:","sidebar":"tutorialSidebar"},"docs/data_integrations/mongodb":{"id":"docs/data_integrations/mongodb","title":"MongoDB","description":"In general the MongoDB query API works exactly as pymongo, with the exception that:","sidebar":"tutorialSidebar"},"docs/data_integrations/mysql":{"id":"docs/data_integrations/mysql","title":"MySQL","description":"Connecting:","sidebar":"tutorialSidebar"},"docs/data_integrations/pandas":{"id":"docs/data_integrations/pandas","title":"Pandas","description":"Although pandas is not a database, it came come in very handy for testing.","sidebar":"tutorialSidebar"},"docs/data_integrations/postgresql":{"id":"docs/data_integrations/postgresql","title":"PostgreSQL","description":"Connecting:","sidebar":"tutorialSidebar"},"docs/data_integrations/snowflake":{"id":"docs/data_integrations/snowflake","title":"Snowflake","description":"Connecting:","sidebar":"tutorialSidebar"},"docs/data_integrations/sql":{"id":"docs/data_integrations/sql","title":"SQL","description":"superduperdb supports SQL databases via the ibis project.","sidebar":"tutorialSidebar"},"docs/data_integrations/sqlite":{"id":"docs/data_integrations/sqlite","title":"SQLite","description":"Connecting:","sidebar":"tutorialSidebar"},"docs/data_integrations/supported_query_APIs":{"id":"docs/data_integrations/supported_query_APIs","title":"Community support","description":"In order to specify the action of models on the data, we provide an interface to pythonic ecosystem query APIs."},"docs/faq":{"id":"docs/faq","title":"FAQ","description":"Learn more about SuperDuperDB.","sidebar":"tutorialSidebar"},"docs/fundamentals/architecture":{"id":"docs/fundamentals/architecture","title":"Architecture","description":"Here is a detailed view of the superduperdb architecture:"},"docs/fundamentals/component_abstraction":{"id":"docs/fundamentals/component_abstraction","title":"Components","description":"A Component is an object which is a combination of JSON-able parameters, and classes which are not","sidebar":"tutorialSidebar"},"docs/fundamentals/component_versioning":{"id":"docs/fundamentals/component_versioning","title":"Component versioning","description":"Whenever a Component is created (see here for overview of Component classes),","sidebar":"tutorialSidebar"},"docs/fundamentals/datalayer_overview":{"id":"docs/fundamentals/datalayer_overview","title":"Datalayer","description":"The Datalayer is the principle point of entry in superduperdb for:","sidebar":"tutorialSidebar"},"docs/fundamentals/design":{"id":"docs/fundamentals/design","title":"Design","description":"Architecture","sidebar":"tutorialSidebar"},"docs/fundamentals/document_encoder_abstraction":{"id":"docs/fundamentals/document_encoder_abstraction","title":"Encoding data","description":"In AI, typical types of data are:","sidebar":"tutorialSidebar"},"docs/fundamentals/glossary":{"id":"docs/fundamentals/glossary","title":"Fundamentals","description":"Glossary","sidebar":"tutorialSidebar"},"docs/fundamentals/predictors_and_models":{"id":"docs/fundamentals/predictors_and_models","title":"Predictors and Models","description":"Predictors","sidebar":"tutorialSidebar"},"docs/fundamentals/procedural_vs_declarative_api":{"id":"docs/fundamentals/procedural_vs_declarative_api","title":"Procedural and Declarative API","description":"superduperdb provides 2 principle approaches for applying AI to the database","sidebar":"tutorialSidebar"},"docs/fundamentals/vector_search_algorithm":{"id":"docs/fundamentals/vector_search_algorithm","title":"Vector-search","description":"SuperDuperDB allows users to implement vector-search in their database by either","sidebar":"tutorialSidebar"},"docs/get_started/installation":{"id":"docs/get_started/installation","title":"Installation","description":"There are two ways to get started:","sidebar":"tutorialSidebar"},"docs/get_started/minimum_working_example":{"id":"docs/get_started/minimum_working_example","title":"Minimum working example","description":"To check that everything is working correctly cut and paste this code into a Jupyter notebook.","sidebar":"tutorialSidebar"},"docs/get_started/quickstart":{"id":"docs/get_started/quickstart","title":"Quickstart","description":"Follow these steps to quickly get started:","sidebar":"tutorialSidebar"},"docs/intro":{"id":"docs/intro","title":"Welcome to SuperDuperDB!","description":"What is SuperDuperDB?","sidebar":"tutorialSidebar"},"docs/production/change_data_capture":{"id":"docs/production/change_data_capture","title":"Setting up SuperDuperDB as a change-data-capture daemon","description":"This functionality is currently for MongoDB only","sidebar":"tutorialSidebar"},"docs/production/command_line_interface":{"id":"docs/production/command_line_interface","title":"Command line interface","description":"Start change-data-capture (CDC)","sidebar":"tutorialSidebar"},"docs/production/developer_vs_production_mode":{"id":"docs/production/developer_vs_production_mode","title":"Developer vs. production mode","description":"Please refer to the architecture page for a detailed description of the superduperdb architecture.","sidebar":"tutorialSidebar"},"docs/production/non_blocking_dask_jobs":{"id":"docs/production/non_blocking_dask_jobs","title":"Running non-blocking dask computations in the background","description":"superduperdb offers the possiblity to run all long running blocking jobs in the background via dask.","sidebar":"tutorialSidebar"},"docs/production/vector_comparison_service":{"id":"docs/production/vector_comparison_service","title":"Vector-searcher service","description":"The vector-comparison service is a standalone,","sidebar":"tutorialSidebar"},"docs/setup/configuration":{"id":"docs/setup/configuration","title":"Configure","description":"SuperDuperDB provides a range of configurable options for setting","sidebar":"tutorialSidebar"},"docs/setup/connecting":{"id":"docs/setup/connecting","title":"Connecting to the Database","description":"In this document we instantiate the variable db based on configuration and overrides.","sidebar":"tutorialSidebar"},"docs/setup/observability":{"id":"docs/setup/observability","title":"System Observability","description":"To enhance the observability of our setup, we\'ve integrated Grafana with Prometheus for monitoring system resources and Loki for centralized logging.","sidebar":"tutorialSidebar"},"docs/setup/sandbox":{"id":"docs/setup/sandbox","title":"Sandbox","description":"The superduperdb open-source repository comes with a sandbox testing","sidebar":"tutorialSidebar"},"docs/setup/testing":{"id":"docs/setup/testing","title":"Testing","description":"Make sure you have the following prerequistes","sidebar":"tutorialSidebar"},"docs/walkthrough/ai_apis":{"id":"docs/walkthrough/ai_apis","title":"Using AI APIs as Predictor descendants","description":"In SuperDuperDB, developers are able to interact with popular AI API providers, in a way very similar to"},"docs/walkthrough/ai_models":{"id":"docs/walkthrough/ai_models","title":"Adding Models to the Database","description":"SuperDuperDB integrates with both AI models and AI APIs","sidebar":"tutorialSidebar"},"docs/walkthrough/apply_models":{"id":"docs/walkthrough/apply_models","title":"Applying the models","description":"Model and Predictor instances may be applied directly to data in the database without first fetching the data client-side.","sidebar":"tutorialSidebar"},"docs/walkthrough/creating_stacks_of_functionality":{"id":"docs/walkthrough/creating_stacks_of_functionality","title":"Creating complex stacks of functionality","description":"With the declarative API, it\'s possible to create multiple","sidebar":"tutorialSidebar"},"docs/walkthrough/daemonizing_models_with_listeners":{"id":"docs/walkthrough/daemonizing_models_with_listeners","title":"Daemonizing .predict with listeners","description":"In many AI applications, it\'s important that a catalogue of predictions is maintained for"},"docs/walkthrough/data_encodings_and_schemas":{"id":"docs/walkthrough/data_encodings_and_schemas","title":"Setting up tables and encodings","description":"superduperdb has flexible support for data-types. In both MongoDB and SQL databases,","sidebar":"tutorialSidebar"},"docs/walkthrough/encoding_special_data_types":{"id":"docs/walkthrough/encoding_special_data_types","title":"Inserting images, audio, video and other special data","description":"An initial step in working with superduperdb"},"docs/walkthrough/inserting_data":{"id":"docs/walkthrough/inserting_data","title":"Inserting data","description":"After configuring and connecting, you\'re ready to insert some data.","sidebar":"tutorialSidebar"},"docs/walkthrough/linking_interdependent_models":{"id":"docs/walkthrough/linking_interdependent_models","title":"Configuring models to ingest features from other models","description":"Sometimes the outputs of one model should be \\"chained together\\" to become inputs of another model.","sidebar":"tutorialSidebar"},"docs/walkthrough/referring_to_data_from_diverse_sources":{"id":"docs/walkthrough/referring_to_data_from_diverse_sources","title":"Working with external data sources","description":"This functionality is currently supported for MongoDB only","sidebar":"tutorialSidebar"},"docs/walkthrough/selecting_data":{"id":"docs/walkthrough/selecting_data","title":"Selecting data","description":"After inserting data to superduperdb, it may be queried with a Select query.","sidebar":"tutorialSidebar"},"docs/walkthrough/serialization":{"id":"docs/walkthrough/serialization","title":"Serializing components with SuperDuperDB","description":"When adding a component to SuperDuperDB,","sidebar":"tutorialSidebar"},"docs/walkthrough/training_models":{"id":"docs/walkthrough/training_models","title":"Training models directly on your datastore","description":"Similarly to applying models to create predictions, training models is possible both procedurally and declaratively in superduperdb.","sidebar":"tutorialSidebar"},"docs/walkthrough/tutorial_walkthrough":{"id":"docs/walkthrough/tutorial_walkthrough","title":"How-To Guide","description":"Start here","sidebar":"tutorialSidebar"},"docs/walkthrough/using_hybrid_storage_to_handle_large_data_blobs":{"id":"docs/walkthrough/using_hybrid_storage_to_handle_large_data_blobs","title":"Working with and inserting large pieces of data","description":"This functionality is currently only supported by the MongDB API","sidebar":"tutorialSidebar"},"docs/walkthrough/vector_search":{"id":"docs/walkthrough/vector_search","title":"Setting up and accessing vector-search","description":"Vector-search refers to the task of searching through vectors","sidebar":"tutorialSidebar"},"use_cases/classical_tasks/mnist_torch":{"id":"use_cases/classical_tasks/mnist_torch","title":"Training and Managing MNIST Predictions on MongoDB","description":"This notebook guides you through the implementation of a classic machine learning task: MNIST handwritten digit recognition. The twist? We perform the task directly in a database using SuperDuperDB.","sidebar":"tutorialSidebar"},"use_cases/classical_tasks/resnet_features":{"id":"use_cases/classical_tasks/resnet_features","title":"Building an Image Feature-Store Using Torchvision on MongoDB","description":"In this example, we show how to utilize a pre-trained network from torchvision to produce image features. The images are automatically fetched and stored in MongoDB. We use a subset of the CoCo dataset (https://cocodataset.org/#home) to illustrate the process.","sidebar":"tutorialSidebar"},"use_cases/classical_tasks/sentiment_analysis_use_case":{"id":"use_cases/classical_tasks/sentiment_analysis_use_case","title":"Building Sentiment Analyser Using transformers on MongoDB","description":"In this document, we\'re doing sentiment analysis using Hugging Face\'s transformers library. We demonstrate that you can perform this task seamlessly in SuperDuperDB, using MongoDB to store the data.","sidebar":"tutorialSidebar"},"use_cases/classical_tasks/transfer_learning":{"id":"use_cases/classical_tasks/transfer_learning","title":"Transfer-Learning Using Transformers and Scikit-Learn on MongoDB","description":"In this notebook, we will explore the process of transfer learning using SuperDuperDB. We will demonstrate how to connect to a MongoDB datastore, load a dataset, create a SuperDuperDB model based on Sentence Transformers, train a downstream model using Scikit-Learn, and apply the trained model to the database. Transfer learning is a powerful technique that can be used in various applications, such as vector search and downstream learning tasks.","sidebar":"tutorialSidebar"},"use_cases/productionization/sandbox-example":{"id":"use_cases/productionization/sandbox-example","title":"SuperDuperDB: cluster usage","description":"SuperDuperDB allows developers, on the one hand to experiment and setup models quickly in scripts and notebooks, and on the other hand deploy persistent services, which are intended to \\"always\\" be on. These persistent services are:","sidebar":"tutorialSidebar"},"use_cases/question-answering/chat_with_your_database":{"id":"use_cases/question-answering/chat_with_your_database","title":"Chatting with your SnowFlakes Database Using OpenAI","description":"Imagine chatting with your database using just a few lines of code. Sounds unbelievable, right? Well, believe it! We\'ll show you how you can effortlessly chat with a huge database containing 10 million business records\u2014all with just a few lines of SuperDuperDB code.","sidebar":"tutorialSidebar"},"use_cases/question-answering/Chatbot":{"id":"use_cases/question-answering/Chatbot","title":"Building Q&A Assistant Using OpenAI on MongoDB","description":"This notebook is designed to demonstrate how to implement a document Question-and-Answer (Q&A) task using SuperDuperDB in conjunction with OpenAI and MongoDB. It provides a step-by-step guide and explanation of each component involved in the process.","sidebar":"tutorialSidebar"},"use_cases/question-answering/voice_memos":{"id":"use_cases/question-answering/voice_memos","title":"Building Voice-Memo Assistant on MongoDB","description":"Cataloguing voice-memos for a self managed personal assistant","sidebar":"tutorialSidebar"},"use_cases/sql_examples/multi-modal-duckdb":{"id":"use_cases/sql_examples/multi-modal-duckdb","title":"Building a Multimodel Vector-Search on DuckDB","description":"SuperDuperDB offers the flexibility to connect to various SQL databases. Check out range of supported SQL databases here","sidebar":"tutorialSidebar"},"use_cases/sql_examples/snowflake-example":{"id":"use_cases/sql_examples/snowflake-example","title":"Building a Vector-Search on Snowflake","description":"In this use-case we describe how to implement vector-search using superduperdb on Snowflake.","sidebar":"tutorialSidebar"},"use_cases/vector_search/chunked_vector_search":{"id":"use_cases/vector_search/chunked_vector_search","title":"Building a Vector-Search Using Chunked Data on MongoDB","description":"Let\'s find specific text within documents using vector-search. In this","sidebar":"tutorialSidebar"},"use_cases/vector_search/multimodal_image_search_clip":{"id":"use_cases/vector_search/multimodal_image_search_clip","title":"Building a Multimodal Vector-Search Using CLIP on MongoDB","description":"This notebook demonstrates how SuperDuperDB can perform multimodal searches using the VectorIndex. It highlights SuperDuperDB\'s flexibility in integrating different models for vectorizing diverse queries during search and inference. In this example, we utilize the CLIP multimodal architecture.","sidebar":"tutorialSidebar"},"use_cases/vector_search/plain_vector_search":{"id":"use_cases/vector_search/plain_vector_search","title":"Building a Vanilla Text Vector-Search on MongoDB","description":"This guide shows how to use SuperDuperDB for vector search, a powerful technique to find similar documents. We\'ll cover the setup and demonstrate searching a dataset of documents. Vector search with SuperDuperDB is a useful tool in various situations:","sidebar":"tutorialSidebar"},"use_cases/vector_search/video_search":{"id":"use_cases/vector_search/video_search","title":"Build in Video Vector-Search with Text on MongoDB","description":"This notebook guides you through the process of searching for specific textual information within videos and retrieving relevant video segments. To achieve this, we leverage various libraries and techniques, including:","sidebar":"tutorialSidebar"}}}')}}]);