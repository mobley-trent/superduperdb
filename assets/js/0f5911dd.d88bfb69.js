"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[2842],{24541:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>l});var i=t(85893),o=t(11151);const s={},a="MNIST classifier",r={id:"use_cases/classical_tasks/mnist_torch",title:"MNIST classifier",description:"Training and Managing MNIST Predictions in SuperDuperDB",source:"@site/content/use_cases/classical_tasks/mnist_torch.md",sourceDirName:"use_cases/classical_tasks",slug:"/use_cases/classical_tasks/mnist_torch",permalink:"/docs/use_cases/classical_tasks/mnist_torch",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/use_cases/classical_tasks/mnist_torch.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Classical ML",permalink:"/docs/category/classical-ml-1"},next:{title:"Image features",permalink:"/docs/use_cases/classical_tasks/resnet_features"}},c={},l=[{value:"Training and Managing MNIST Predictions in SuperDuperDB",id:"training-and-managing-mnist-predictions-in-superduperdb",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Connect to datastore",id:"connect-to-datastore",level:2},{value:"Load Dataset",id:"load-dataset",level:2},{value:"Build Model",id:"build-model",level:2},{value:"Train Model",id:"train-model",level:2},{value:"Monitoring Training Efficiency",id:"monitoring-training-efficiency",level:2},{value:"On-the-fly Predictions",id:"on-the-fly-predictions",level:2},{value:"Verification",id:"verification",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"mnist-classifier",children:"MNIST classifier"}),"\n",(0,i.jsx)(n.h2,{id:"training-and-managing-mnist-predictions-in-superduperdb",children:"Training and Managing MNIST Predictions in SuperDuperDB"}),"\n",(0,i.jsx)(n.p,{children:"This notebook guides you through the implementation of a classic machine learning task: MNIST handwritten digit recognition. The twist? We perform the task directly in a database using SuperDuperDB."}),"\n",(0,i.jsx)(n.p,{children:"This example makes it easy to connect any of your image recognition\nmodel directly to your database in real-time. With SuperDuperDB, you can\nskip complicated MLOps pipelines. It's a new straightforward way to\nintegrate your AI model with your data, ensuring simplicity, efficiency\nand speed."}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"Before diving into the implementation, ensure that you have the\nnecessary libraries installed by running the following commands:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"!pip install superduperdb\n!pip install torch torchvision matplotlib\n"})}),"\n",(0,i.jsx)(n.h2,{id:"connect-to-datastore",children:"Connect to datastore"}),"\n",(0,i.jsxs)(n.p,{children:["First, we need to establish a connection to a MongoDB datastore via\nSuperDuperDB. You can configure the ",(0,i.jsx)(n.code,{children:"MongoDB_URI"})," based on your specific\nsetup."]}),"\n",(0,i.jsx)(n.p,{children:"Here are some examples of MongoDB URIs:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["For testing (default connection): ",(0,i.jsx)(n.code,{children:"mongomock://test"})]}),"\n",(0,i.jsxs)(n.li,{children:["Local MongoDB instance: ",(0,i.jsx)(n.code,{children:"mongodb://localhost:27017"})]}),"\n",(0,i.jsxs)(n.li,{children:["MongoDB with authentication:\n",(0,i.jsx)(n.code,{children:"mongodb://superduper:superduper@mongodb:27017/documents"})]}),"\n",(0,i.jsxs)(n.li,{children:["MongoDB Atlas:\n",(0,i.jsx)(n.code,{children:"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>"})]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from superduperdb import superduper\nfrom superduperdb.backends.mongodb import Collection\nimport os\n\nmongodb_uri = os.getenv("MONGODB_URI","mongomock://test")\n\n# SuperDuperDB, now handles your MongoDB database\n# It just super dupers your database \ndb = superduper(mongodb_uri)\n\n# Create a collection for MNIST\nmnist_collection = Collection(\'mnist\')\n'})}),"\n",(0,i.jsx)(n.h2,{id:"load-dataset",children:"Load Dataset"}),"\n",(0,i.jsxs)(n.p,{children:["After establishing a connection to MongoDB, the next step is to load the\nMNIST dataset. SuperDuperDB's strength lies in handling diverse data\ntypes, especially those that are challenging. To achieve this, we use an\n",(0,i.jsx)(n.code,{children:"Encoder"})," in conjunction with ",(0,i.jsx)(n.code,{children:"Document"})," wrappers. These components\nallow Python dictionaries containing non-JSONable or bytes objects to be\nseamlessly inserted into the underlying data infrastructure."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import torchvision\nfrom superduperdb.ext.pillow import pil_image\nfrom superduperdb import Document\nfrom superduperdb.backends.mongodb import Collection\n\nimport random\n\n# Load MNIST images as Python objects using the Python Imaging Library.\n# Each MNIST item is a tuple (image, label)\nmnist_data = list(torchvision.datasets.MNIST(root='./data', download=True))\n\n# Create a list of Document instances from the MNIST data\n# Each Document has an 'img' field (encoded using the Pillow library) and a 'class' field\ndocument_list = [Document({'img': pil_image(x[0]), 'class': x[1]}) for x in mnist_data]\n\n# Shuffle the data and select a subset of 1000 documents\nrandom.shuffle(document_list)\ndata = document_list[:1000]\n\n# Insert the selected data into the mnist_collection which we mentioned before like: mnist_collection = Collection('mnist')\ndb.execute(\n    mnist_collection.insert_many(data[:-100]),  # Insert all but the last 100 documents\n    encoders=(pil_image,) # Encode images using the Pillow library.\n)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Now that the images and their classes are inserted into the database, we can query the data in its original format. Particularly, we can use the ",(0,i.jsx)(n.code,{children:"PIL.Image"})," instances to inspect the data."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Get and display one of the images\nr = db.execute(mnist_collection.find_one())\nr.unpack()['img']\n"})}),"\n",(0,i.jsx)(n.h2,{id:"build-model",children:"Build Model"}),"\n",(0,i.jsxs)(n.p,{children:["Following that, we build our machine learning model. SuperDuperDB\nconveniently supports various frameworks, and for this example, we opt\nfor PyTorch, a suitable choice for computer vision tasks. In this\ninstance, we combine ",(0,i.jsx)(n.code,{children:"torch"})," with ",(0,i.jsx)(n.code,{children:"torchvision"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["To facilitate communication with the SuperDuperDB ",(0,i.jsx)(n.code,{children:"Datalayer"}),", we design ",(0,i.jsx)(n.code,{children:"postprocess"})," and ",(0,i.jsx)(n.code,{children:"preprocess"})," functions. These functions are then encapsulated with the model, preprocessing, and postprocessing steps to create a native SuperDuperDB handler."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import torch\n\n# Define the LeNet-5 architecture for image classification\nclass LeNet5(torch.nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        # Layer 1\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n            torch.nn.BatchNorm2d(6),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n        # Layer 2\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n            torch.nn.BatchNorm2d(16),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n        # Fully connected layers\n        self.fc = torch.nn.Linear(400, 120)\n        self.relu = torch.nn.ReLU()\n        self.fc1 = torch.nn.Linear(120, 84)\n        self.relu1 = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(84, num_classes)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.relu(out)\n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        return out\n\n# Postprocess function for the model output    \ndef postprocess(x):\n    return int(x.topk(1)[1].item())\n\n# Preprocess function for input data\ndef preprocess(x):\n    return torchvision.transforms.Compose([\n        torchvision.transforms.Resize((32, 32\n\n)),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n    )(x)\n\n# Create an instance of the LeNet-5 model\nlenet_model = LeNet5(10)\n\n# Create a SuperDuperDB model with the LeNet-5 model, preprocess, and postprocess functions\n# Specify 'preferred_devices' as ('cpu',) indicating CPU preference\nmodel = superduper(lenet_model, preprocess=preprocess, postprocess=postprocess, preferred_devices=('cpu',))\ndb.add(model)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"train-model",children:"Train Model"}),"\n",(0,i.jsxs)(n.p,{children:['Now we are ready to "train" or "fit" the model. Trainable models in\nSuperDuperDB come with a sklearn-like ',(0,i.jsx)(n.code,{children:".fit"})," method."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from torch.nn.functional import cross_entropy\n\nfrom superduperdb import Metric\nfrom superduperdb import Dataset\nfrom superduperdb.ext.torch.model import TorchTrainerConfiguration\n\n# Fit the model to the training data\njob = model.fit(\n    X='img', # Feature matrix used as input data \n    y='class', # Target variable for training\n    db=db, # Database used for data retrieval\n    select=mnist_collection.find(), # Select the dataset from the 'mnist_collection'\n    configuration=TorchTrainerConfiguration(\n        identifier='my_configuration', # Unique identifier for the training configuration\n        objective=cross_entropy, # The objective function (cross-entropy in this case)\n        loader_kwargs={'batch_size': 10}, # DataLoader keyword arguments, batch size is set to 10\n        max_iterations=10, # Maximum number of training iterations\n        validation_interval=5, # Interval for validation during training\n    ),\n    metrics=[Metric(identifier='acc', object=lambda x, y: sum([xx == yy for xx, yy in zip(x, y)]) / len(x))], # Define a custom accuracy metric for evaluation during training\n    validation_sets=[\n        # Define a validation dataset using a subset of data with '_fold' equal to 'valid'\n        Dataset(\n            identifier='my_valid',\n            select=Collection('mnist').find({'_fold': 'valid'}),\n        )\n    ],\n    distributed=False, # Set to True if distributed training is enabled\n)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"monitoring-training-efficiency",children:"Monitoring Training Efficiency"}),"\n",(0,i.jsx)(n.p,{children:"You can monitor the training efficiency with visualization tools like\nMatplotlib:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from matplotlib import pyplot as plt\n\n# Load the model from the database\nmodel = db.load('model', model.identifier)\n\n# Plot the accuracy values\nplt.plot(model.metric_values['my_valid/acc'])\nplt.show()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"on-the-fly-predictions",children:"On-the-fly Predictions"}),"\n",(0,i.jsxs)(n.p,{children:["After training the model, you can continuously predict on new data as it arrives. By activating a ",(0,i.jsx)(n.code,{children:"listener"})," for the database, the model can make predictions on incoming data changes without having to load all the data client-side. The listen toggle triggers the model to predict based on updates in the incoming data."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"model.predict(\n    X='img', # Input feature  \n    db=db,  # Database used for data retrieval\n    select=mnist_collection.find(), # Select the dataset\n    listen=True, # Continuous predictions on incoming data \n    max_chunk_size=100, # Number of predictions to return at once\n)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["We can see that predictions are available in ",(0,i.jsx)(n.code,{children:"_outputs.img.lenet5"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Execute find_one() to retrieve a single document from the 'mnist_collection'. \nr = db.execute(mnist_collection.find_one({'_fold': 'valid'}))\n\n# Unpack the document and extract its content\nr.unpack()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"verification",children:"Verification"}),"\n",(0,i.jsx)(n.p,{children:'The models "activated" can be seen here:'}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Show the status of the listener\ndb.show('listener')\n"})}),"\n",(0,i.jsx)(n.p,{children:"We can verify that the model is activated, by inserting the rest of the\ndata:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Iterate over the last 100 elements in the 'data' list\nfor r in data[-100:]:\n    # Update the 'update' field to True for each document\n    r['update'] = True\n\n# Insert the updated documents (with 'update' set to True) into the 'mnist_collection'\ndb.execute(mnist_collection.insert_many(data[-100:]))\n"})}),"\n",(0,i.jsx)(n.p,{children:"You can see that the inserted data, are now also populated with\npredictions:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Execute find_one() to retrieve a single sample document from 'mnist_collection'\n# where the 'update' field is True\nsample_document = db.execute(mnist_collection.find_one({'update': True}))['_outputs']\n\n# A sample document \nprint(sample_document)\n"})})]})}function u(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>a});var i=t(67294);const o={},s=i.createContext(o);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);